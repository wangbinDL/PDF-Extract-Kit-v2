Search.setIndex({"alltitles": {"<a href='https://xtuner.readthedocs.io/en/latest/'>English</a>": [[38, null]], "<a href='https://xtuner.readthedocs.io/zh_CN/latest/'>\u7b80\u4f53\u4e2d\u6587</a>": [[38, "id1"]], "Accelerate chat by LMDeploy": [[11, null]], "Accelerating Training": [[13, "accelerating-training"], [34, "accelerating-training"]], "Acceleration": [[23, null]], "Arxiv Gentitle": [[48, "arxiv-gentitle"]], "Benchmark": [[0, null]], "Best Practices": [[20, "best-practices"]], "Case 1": [[24, null]], "Case 2": [[25, null]], "Case 3": [[26, null]], "Case 4": [[27, null]], "Changelog": [[31, null]], "Chat": [[23, null]], "Chat with Agent": [[9, null]], "Chat with InternLM": [[46, "chat-with-internlm"]], "Chat with LLM": [[10, null]], "Chat with Llama2": [[46, "chat-with-llama2"]], "Chat with Qwen": [[46, "chat-with-qwen"]], "Chat with VLM": [[12, null]], "Chat with fine-tuned LLMs": [[46, null]], "Chat with the model": [[22, "chat-with-the-model"]], "Chinese Lawyer": [[48, "chinese-lawyer"]], "Choosing the prompt template": [[53, "choosing-the-prompt-template"]], "Custom Agent Dataset": [[39, null]], "Custom Pretrain Dataset": [[40, null]], "Custom SFT Dataset": [[41, null]], "DPO": [[23, null]], "Dataset Format": [[47, null], [51, "dataset-format"]], "Dataset Prepare": [[48, null]], "DeepSpeed": [[1, null]], "Documentation": [[23, "documentation"]], "Download from HuggingFace": [[22, "download-from-huggingface"], [22, "id1"]], "Download from ModelScope": [[22, "download-from-modelscope"], [22, "id2"]], "Evaluate with OpenCompass": [[19, null]], "Evaluation": [[23, null]], "Evaluation during training": [[16, null]], "Features of DPO Training in XTuner": [[14, "features-of-dpo-training-in-xtuner"]], "Features of Reward Model Training in XTuner": [[35, "features-of-reward-model-training-in-xtuner"]], "File structure": [[48, "file-structure"], [48, "id1"]], "Fine-tune the pretrained LLMs": [[49, null]], "Finetune": [[48, "finetune"]], "Flash Attention": [[2, null]], "Get Started": [[23, null]], "Getting Started": [[14, "getting-started"], [35, "getting-started"]], "Highlights": [[31, "highlights"]], "HuggingFace datasets": [[48, "huggingface-datasets"]], "HyperParameters": [[3, null]], "Incremental Pre-training Data Pipeline": [[50, null]], "Incremental Pre-training Dataset Format": [[47, "incremental-pre-training-dataset-format"]], "Installation": [[20, null]], "Installation Process": [[20, "installation-process"]], "InternEVO Migration": [[29, null]], "InternEvo Migration": [[23, null]], "InternLM-20B": [[46, "internlm-20b"]], "InternLM-7B": [[46, "internlm-7b"]], "InternLM-Chat-20B": [[46, "internlm-chat-20b"]], "InternLM-Chat-7B": [[46, "internlm-chat-7b"]], "Introduction to DPO": [[14, null]], "Introduction to Reward Model": [[35, null]], "LLaVA dataset": [[48, "llava-dataset"]], "Length Grouped Sampler": [[4, null]], "Llama-2-7B": [[46, "llama-2-7b"]], "LoRA Merge": [[22, "lora-merge"]], "Loss Function": [[13, "loss-function"], [34, "loss-function"]], "MMBench (VLM)": [[17, null]], "MMLU (LLM)": [[18, null]], "MOSS-003-SFT": [[48, "moss-003-sft"]], "Method 1": [[47, "method-1"]], "Method 2": [[47, "method-2"]], "Method in XTuner": [[47, "method-in-xtuner"]], "Model Conversion": [[15, "model-conversion"], [37, "model-conversion"]], "Model Convert": [[22, "model-convert"]], "Model Convert + LoRA Merge": [[22, "model-convert-lora-merge"]], "Models": [[23, null]], "Modify DPO Training Configuration": [[13, null]], "Modify Reward Model Training Configuration": [[34, null]], "Modify Settings": [[42, null]], "Modify the config": [[22, "modify-the-config"]], "Modifying the Model": [[13, "modifying-the-model"], [34, "modifying-the-model"]], "Multi-modal Dataset": [[43, null]], "Multi-turn Dialogue Data Pipeline": [[52, null]], "Multi-turn Dialogue Dataset Format": [[47, "multi-turn-dialogue-dataset-format"]], "Open Source Datasets": [[44, null]], "Open-source Models": [[35, "open-source-models"]], "Others": [[48, "others"]], "Overview": [[14, "overview"], [21, null], [35, "overview"], [36, "overview"]], "Pack to Max Length": [[5, null]], "Preference Dataset": [[36, null]], "Preparation": [[23, null]], "Prepare the config": [[22, "prepare-the-config"]], "Prepare the fine-tuning dataset": [[22, "prepare-the-fine-tuning-dataset"]], "Prepare the model weights": [[22, "prepare-the-model-weights"]], "Preparing Configuration File": [[15, "preparing-configuration-file"]], "Preparing Configuration Files": [[37, "preparing-configuration-files"]], "Preparing Pretrained Model Weights": [[15, "preparing-pretrained-model-weights"], [37, "preparing-pretrained-model-weights"]], "Preparing Training Data": [[15, "preparing-training-data"], [37, "preparing-training-data"]], "Pretrain": [[48, "pretrain"]], "Pretrained Model": [[32, null]], "Prompt Template": [[33, null], [53, null]], "QLoRA Fine-tune Baichuan": [[49, "qlora-fine-tune-baichuan"]], "QLoRA Fine-tune InternLM": [[49, "qlora-fine-tune-internlm"]], "QLoRA Fine-tune Llama2": [[49, "qlora-fine-tune-llama2"]], "QLoRA Fine-tune Qwen": [[49, "qlora-fine-tune-qwen"]], "Quick Start Guide for Reward Model": [[37, null]], "Quick Start with DPO": [[15, null]], "Quickstart": [[22, null]], "Qwen-7B": [[46, "qwen-7b"]], "RefCOCO dataset": [[48, "refcoco-dataset"]], "Results": [[53, "results"]], "Reward Model": [[23, null]], "Single-turn Dialogue Data Pipeline": [[54, null]], "Single-turn Dialogue Dataset Format": [[47, "single-turn-dialogue-dataset-format"]], "Start fine-tuning": [[22, "start-fine-tuning"]], "Starting the Training": [[15, "starting-the-training"], [37, "starting-the-training"]], "Step 1, Data Preparation": [[50, "step-1-data-preparation"]], "Step 1, Dataset Preparation": [[52, "step-1-dataset-preparation"], [54, "step-1-dataset-preparation"]], "Step 1, Export the Template Config File": [[51, "step-1-export-the-template-config-file"]], "Step 1, List Candidate Model Names": [[54, "step-1-list-candidate-model-names"]], "Step 1, Map Original Dataset to Standard Format": [[50, "step-1-map-original-dataset-to-standard-format"], [52, "step-1-map-original-dataset-to-standard-format"]], "Step 1, Map the Original Dataset to Standard Format": [[54, "step-1-map-the-original-dataset-to-standard-format"]], "Step 2, Export the Config File": [[54, "step-2-export-the-config-file"]], "Step 2, List Candidate Model Names": [[50, "step-2-list-candidate-model-names"], [50, "id1"], [52, "step-2-list-candidate-model-names"], [52, "id1"], [54, "step-2-list-candidate-model-names"], [54, "id1"]], "Step 2, Modify the Template Config File": [[51, "step-2-modify-the-template-config-file"]], "Step 3, Export the Config File": [[50, "step-3-export-the-config-file"], [50, "id2"], [52, "step-3-export-the-config-file"], [52, "id2"], [54, "step-3-export-the-config-file"], [54, "id2"]], "Step 3, Modify Config File": [[54, "step-3-modify-config-file"]], "Step 3, Start training": [[51, "step-3-start-training"]], "Step 4, Modify Config File": [[52, "step-4-modify-config-file"], [54, "step-4-modify-config-file"]], "Step 4, Modify Config Files": [[52, "step-4-modify-config-files"], [54, "step-4-modify-config-files"]], "Step 4, Modify the Config File": [[50, "step-4-modify-the-config-file"]], "Step 4, Modify the config file": [[50, "id3"]], "Step 5, Check custom Dataset (Optional)": [[50, "step-5-check-custom-dataset-optional"], [50, "id4"], [52, "step-5-check-custom-dataset-optional"], [52, "id3"], [54, "step-5-check-custom-dataset-optional"], [54, "id3"]], "Structure": [[53, "structure"]], "Supported Models": [[30, null]], "Train Extreme Long Sequence": [[6, null]], "Train Large-scale Dataset": [[7, null]], "Training": [[23, null]], "Training Data": [[13, "training-data"], [34, "training-data"]], "Training with Custom Data": [[36, "training-with-custom-data"]], "Training with Open Source Datasets": [[36, "training-with-open-source-datasets"]], "Tutorial": [[51, null]], "Using Alpaca Format Custom Datasets": [[54, "using-alpaca-format-custom-datasets"]], "Using Custom Datasets": [[50, "using-custom-datasets"], [52, "using-custom-datasets"], [54, "using-custom-datasets"]], "Using Dataset in HuggingFace Hub": [[50, "using-dataset-in-huggingface-hub"], [52, "using-dataset-in-huggingface-hub"], [54, "using-dataset-in-huggingface-hub"]], "Using Other Format Custom Datasets": [[54, "using-other-format-custom-datasets"]], "Varlen Flash Attention": [[8, null]], "Verify the installation": [[20, "verify-the-installation"]], "Visualization": [[45, null]], "Welcome to XTuner\u2019s documentation!": [[23, null]], "What is XTuner": [[21, "what-is-xtuner"]], "ftdp": [[28, null]], "v0.1.0 (2023.08.30)": [[31, "v0-1-0-2023-08-30"]]}, "docnames": ["acceleration/benchmark", "acceleration/deepspeed", "acceleration/flash_attn", "acceleration/hyper_parameters", "acceleration/length_grouped_sampler", "acceleration/pack_to_max_length", "acceleration/train_extreme_long_sequence", "acceleration/train_large_scale_dataset", "acceleration/varlen_flash_attn", "chat/agent", "chat/llm", "chat/lmdeploy", "chat/vlm", "dpo/modify_settings", "dpo/overview", "dpo/quick_start", "evaluation/hook", "evaluation/mmbench", "evaluation/mmlu", "evaluation/opencompass", "get_started/installation", "get_started/overview", "get_started/quickstart", "index", "internevo_migration/ftdp_dataset/Case1", "internevo_migration/ftdp_dataset/Case2", "internevo_migration/ftdp_dataset/Case3", "internevo_migration/ftdp_dataset/Case4", "internevo_migration/ftdp_dataset/ftdp", "internevo_migration/internevo_migration", "models/supported", "notes/changelog", "preparation/pretrained_model", "preparation/prompt_template", "reward_model/modify_settings", "reward_model/overview", "reward_model/preference_data", "reward_model/quick_start", "switch_language", "training/custom_agent_dataset", "training/custom_pretrain_dataset", "training/custom_sft_dataset", "training/modify_settings", "training/multi_modal_dataset", "training/open_source_dataset", "training/visualization", "user_guides/chat", "user_guides/dataset_format", "user_guides/dataset_prepare", "user_guides/finetune", "user_guides/incremental_pretraining", "user_guides/intern_repo_dataset", "user_guides/multi_turn_conversation", "user_guides/prompt_template", "user_guides/single_turn_conversation"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["acceleration/benchmark.rst", "acceleration/deepspeed.rst", "acceleration/flash_attn.rst", "acceleration/hyper_parameters.rst", "acceleration/length_grouped_sampler.rst", "acceleration/pack_to_max_length.rst", "acceleration/train_extreme_long_sequence.rst", "acceleration/train_large_scale_dataset.rst", "acceleration/varlen_flash_attn.rst", "chat/agent.md", "chat/llm.md", "chat/lmdeploy.md", "chat/vlm.md", "dpo/modify_settings.md", "dpo/overview.md", "dpo/quick_start.md", "evaluation/hook.md", "evaluation/mmbench.md", "evaluation/mmlu.md", "evaluation/opencompass.md", "get_started/installation.md", "get_started/overview.md", "get_started/quickstart.md", "index.rst", "internevo_migration/ftdp_dataset/Case1.rst", "internevo_migration/ftdp_dataset/Case2.rst", "internevo_migration/ftdp_dataset/Case3.rst", "internevo_migration/ftdp_dataset/Case4.rst", "internevo_migration/ftdp_dataset/ftdp.rst", "internevo_migration/internevo_migration.rst", "models/supported.md", "notes/changelog.md", "preparation/pretrained_model.rst", "preparation/prompt_template.rst", "reward_model/modify_settings.md", "reward_model/overview.md", "reward_model/preference_data.md", "reward_model/quick_start.md", "switch_language.md", "training/custom_agent_dataset.rst", "training/custom_pretrain_dataset.rst", "training/custom_sft_dataset.rst", "training/modify_settings.rst", "training/multi_modal_dataset.rst", "training/open_source_dataset.rst", "training/visualization.rst", "user_guides/chat.md", "user_guides/dataset_format.md", "user_guides/dataset_prepare.md", "user_guides/finetune.md", "user_guides/incremental_pretraining.md", "user_guides/intern_repo_dataset.md", "user_guides/multi_turn_conversation.md", "user_guides/prompt_template.md", "user_guides/single_turn_conversation.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [14, 15, 22, 35, 36, 37, 47, 48, 50, 52, 53, 54], "0": [13, 20, 22, 37, 48, 50, 52, 53], "0000": 37, "00001": 22, "00002": 22, "00003": 22, "00004": 22, "00005": 22, "00006": 22, "00007": 22, "00008": 22, "0001e": 22, "0010": 37, "0011": 37, "0013": 37, "0016": 37, "002": 54, "0023": 37, "0024": 37, "0025": 37, "0027": 37, "003": [46, 49], "0030": 37, "0031": 37, "0032": 37, "0034": 37, "0044": 37, "0055": 37, "0057": 37, "0066dd": 22, "0068": 22, "0069": 22, "0070": 22, "0071": 22, "0077": 22, "00ffcc": 22, "01": [22, 48, 53], "0117": 37, "01_moss_0709": 48, "02": 22, "03": [22, 37], "0331e": 37, "04": 22, "05": [22, 37], "06": 37, "0653": 22, "07": [22, 37], "08": 22, "09": 22, "1": [13, 15, 20, 22, 23, 34, 35, 37, 48, 53], "10": [20, 22, 37, 52], "100": 22, "103028": 51, "1099ee": 22, "11": 37, "12": 37, "12762": 22, "128002": 34, "13": [22, 51], "136": 51, "13969": 22, "13b": 53, "14": 47, "1405": 37, "14b": 53, "150k": 48, "1512": 22, "15230": 37, "1540e": 37, "16": 37, "1621": 51, "16b": 53, "16th": 47, "17": 37, "18": [22, 37], "18021": 37, "1912": 22, "1_0": 48, "1_8b": [13, 15, 34, 35, 37, 53], "2": [22, 23, 37, 48, 53], "20": [22, 37], "2014": 48, "2017": 48, "2020": [36, 48], "2023": 47, "2024": 22, "2040": 22, "2048": [13, 34], "2049": 37, "2097152": 51, "20b": [35, 53], "21": 22, "22": [22, 37, 51], "24": 22, "25": 37, "2749e": 37, "28": [22, 37], "2816": 22, "29": 22, "2b": 53, "2gb": 22, "3": [13, 20, 22, 23, 34, 36, 37, 47], "30": [22, 37], "30238": 37, "31": 22, "32": [13, 22, 34], "32121": 37, "33": 37, "333": 51, "3352": 22, "34": 22, "34b": 53, "35": [22, 37], "352": 51, "3536e": 37, "36": [22, 37], "37": [22, 37], "38": 22, "39": 22, "4": [23, 37, 47], "40": [22, 37], "40k": [13, 15], "41": 37, "42180": 37, "42186": 37, "45": 37, "46": [22, 37], "4627": 37, "4b": 53, "5": [22, 35, 51, 53], "50": [22, 37], "5000": 37, "51": 22, "512": 51, "52": 54, "52002": 54, "55": 22, "5578": 37, "57": 22, "5795": 22, "58": 22, "59": 37, "5936e": 37, "5968": 37, "5_0": 48, "5b": 53, "6": [35, 52, 53], "60": [22, 37], "6018": 37, "6033": 37, "6049": 22, "6247": 37, "6262": 37, "6270": 37, "6278": 37, "66ccff": 22, "6851": 22, "6900": 22, "6b": 53, "70": [22, 37], "7031": 22, "7047": 22, "7048": 22, "7084": 37, "70b": 53, "7145e": 37, "7166": 37, "720": 22, "7247": 22, "7286": 22, "72b": 53, "7302": 22, "7338": 22, "7383": 22, "7500": 37, "7b": [22, 31, 35, 49, 51, 53], "8": [37, 49, 51], "80": [22, 35], "8037": 22, "815": 37, "8184": 22, "8192": 51, "8460": 22, "8482": 22, "86": 35, "8686": 22, "89": 35, "8b": [15, 34, 35, 37, 53], "8gb": 31, "8x7b": 53, "9": 22, "90": 22, "9000e": 22, "9127": 22, "92527": 34, "932": 37, "9361": 22, "9426e": 22, "9563e": 22, "9580e": 37, "9681e": 22, "969": 37, "9781e": 22, "9819": 22, "9846": [50, 52], "9863e": 22, "992": 37, "9925e": 22, "994": 37, "9969e": 22, "9994e": 22, "A": [22, 36, 53], "As": [36, 47, 50, 54], "By": 35, "For": [13, 14, 15, 22, 31, 34, 35, 36, 37, 47, 48, 50, 52, 54], "IN": 23, "If": [15, 34, 36, 37, 50, 52, 53, 54], "In": [13, 14, 15, 20, 22, 34, 35, 36, 37, 47, 54], "It": [20, 22, 52, 53], "Its": 35, "NOT": 22, "ONE": 23, "Of": 22, "One": 13, "The": [13, 14, 22, 31, 35, 36, 37, 47, 50, 51, 52, 53, 54], "Then": 48, "There": 22, "To": [14, 20, 22, 47], "With": [14, 35], "a800": 37, "abil": [47, 52, 54], "abov": [13, 15, 22, 34, 36, 37, 47, 51], "acc": 37, "access": [46, 49], "accommod": 47, "accord": [13, 37, 50, 52, 54], "accordingli": 34, "achiev": 52, "act": [35, 53], "activ": [20, 51], "actor": 35, "actual": 47, "ad": [34, 36, 53], "adapt": [14, 22, 31, 46], "add": [36, 50], "addit": [14, 22], "addition": [13, 34], "adher": 54, "adjust": [13, 34, 50, 52, 54], "adopt": [36, 47], "adult": 36, "advantag": [14, 35], "aforement": 53, "after": [15, 22, 36, 37, 48, 50, 52, 53, 54], "agent": 23, "ah": 36, "ai": [47, 48, 53], "aim": [47, 50, 51, 54], "albeit": 47, "algorithm": [14, 22, 31, 35, 36], "align": [14, 15, 22, 35], "aliyun": 51, "all": [20, 22, 23, 47, 48], "allow": [14, 35], "along": 36, "alpaca": [46, 48, 49], "alpaca_map_fn": 54, "alreadi": [22, 50, 52, 54], "also": [13, 14, 22, 34, 35, 36, 47, 52, 53], "am": 47, "amalgam": 47, "among": 51, "an": [15, 22, 34, 36, 37, 47, 50, 52, 53, 54], "angel": 36, "ani": [20, 50, 52], "ann": 48, "annot": [35, 48], "anoth": 36, "answer": 47, "anyth": 36, "appear": 53, "append": [34, 52, 53], "appl": [22, 36], "applesauc": 36, "appli": 22, "applic": 35, "appreci": 22, "appropri": [52, 54], "ar": [14, 15, 22, 31, 35, 36, 37, 47, 48, 50, 51, 54], "argilla": [34, 37], "argument": 48, "arixv": 48, "arlington": 36, "around": 47, "artifici": 47, "arxiv": [46, 49], "arxiv_data": 48, "arxiv_gentil": 46, "assist": [22, 36, 47, 52], "assistant1": 47, "assistant2": 47, "assistant3": 47, "assistantn": 47, "associ": 47, "asssist": 47, "assum": 48, "attach": 22, "attent": [13, 14, 23, 34, 35], "attention2": [14, 35], "august": 47, "autom": 47, "automat": [13, 15, 34, 37, 53], "avoid": [13, 14, 34], "b": 20, "babi": 22, "backpropag": 47, "bad": 35, "baichuan": 53, "baichuan2": 53, "baichuan2_chat": 53, "baichuan_7b_qlora_alpaca_enzh_e3": 49, "baichuan_7b_qlora_arxiv_gentitle_e3": 49, "baichuan_7b_qlora_oasst1_e3": 49, "baichuan_chat": 53, "balanc": 47, "barrier": 34, "base": [22, 31, 35, 36, 47, 51, 53], "bash": 48, "bashrc": 51, "basic": [14, 35, 52], "basil": 36, "batch_siz": [13, 34], "becaus": [34, 47, 50], "been": 22, "befor": [22, 52], "before_train": 22, "begin": 22, "below": [22, 47, 48, 50, 53, 54], "benchmark": 23, "benefici": 54, "besid": 14, "best": [23, 35], "beta": 53, "better": [14, 22, 36], "between": [13, 22, 34, 50, 52, 54], "bigcod": 53, "bin": [22, 48], "binar": [34, 37], "blip_laion_cc_sbu_558k": 48, "blip_laion_cc_sbu_558k_meta": 48, "blood": 22, "blue": 22, "bob": 36, "bon": 35, "bond0": 51, "bot": [46, 53], "both": [47, 48], "box": 22, "bradlei": 34, "bright": 22, "build": 47, "build_preference_dataset": [13, 15, 34, 36, 37], "burkelibbei": 22, "c": [20, 22, 48], "cache_dir": 22, "calcul": [34, 36, 46, 51, 52], "calm": 22, "can": [13, 14, 15, 20, 22, 34, 35, 36, 37, 47, 48, 50, 51, 52, 54], "capabl": [14, 22, 35, 47, 50, 52], "case": [20, 23], "categori": 48, "caus": [13, 14, 34, 35], "cd": [20, 48, 51], "certain": 14, "cerulean": 22, "cfg": [15, 20, 22, 37, 50, 51, 52, 54], "chang": [13, 34, 48, 50, 52, 54], "chapter": 21, "chat": [13, 15, 34, 36, 37, 53], "chatglm2": 53, "chatglm3": 53, "chatgpt": 36, "check_custom_dataset": [50, 52, 54], "chees": 36, "chines": 22, "choic": 22, "choos": [13, 15, 22, 37], "chop": 36, "chosen": [13, 14, 34, 35, 36], "chosen_score_mean": 37, "ckpt": [15, 37], "cl": 48, "clean": [34, 37], "clear": [22, 47, 52], "cli": [22, 46, 49], "clone": [20, 22, 48], "close": [35, 50], "cloudi": 47, "cluster": [15, 37], "cn": [15, 22, 37], "co": [15, 22, 37, 48], "coco": 48, "coco_imag": 48, "coco_image_path": 48, "code": [20, 22, 36], "coder": [49, 53], "coeffici": 13, "collate_fn": [13, 34], "color": 22, "colorist": [22, 31, 46, 49], "colors_map_fn": 22, "column": [50, 54], "com": [20, 48], "command": [15, 20, 22, 37, 48, 50, 51, 52, 54], "compar": 47, "complet": [15, 22, 37, 54], "complex": 14, "compon": [35, 47], "comprehens": 47, "compris": 54, "comput": 47, "concaten": [14, 35, 47], "concept": [14, 35], "concurr": 47, "conda": [20, 51], "conda_env_nam": 51, "condit": [14, 35], "conduct": 36, "config": [13, 20, 23, 34, 48], "config_nam": [50, 52, 54], "configur": [14, 20, 22, 23, 35, 36, 50, 52, 54], "configuration_internlm2": 22, "consid": 47, "consist": [47, 52, 53], "constraint": 34, "construct": [35, 50, 52, 54], "consum": 31, "contain": [22, 36, 47, 54], "content": [14, 22, 35, 36, 47], "context": 54, "continu": 50, "control": [13, 36], "conveni": 37, "convers": [22, 23, 36, 47, 50, 52, 54], "conversations_with_tools_with_inner_instruction_no_text2image_train_all_random_meta0": 48, "convert": [14, 15, 23, 36, 37, 48], "copi": [15, 22, 37, 50, 51, 52, 54], "cornel": 48, "corpu": 47, "correct": [22, 37, 50, 52, 54], "correctli": 20, "correspond": [20, 22, 47, 50, 51, 54], "cost": 14, "could": 36, "cours": 22, "cp": 48, "creat": [15, 20, 22, 37, 47], "crimekgassitant\u6e05\u6d17\u540e_52k": 48, "critic": 14, "crucial": [35, 54], "cultiv": 52, "current": [15, 22, 37, 47, 50, 51, 52, 54], "custom": [15, 23, 37], "custom_hook": 50, "custom_map_fn": [50, 52, 54], "cv": 48, "d": [36, 50, 52, 54], "dai": [22, 47], "data": [14, 22, 23, 35, 47, 48, 51], "data_fil": [22, 36, 50, 52, 54], "data_path": [22, 50, 52, 54], "data_tim": [22, 37], "dataload": [13, 22, 34, 36, 50, 52, 54], "dataloader_num_work": [13, 34], "dataset": [13, 14, 15, 23, 31, 34, 35, 37], "dataset_fold": 51, "dataset_info": 22, "dataset_map_fn": [13, 15, 22, 34, 36, 37, 50, 52, 54], "datasetinfohook": 50, "date": [47, 48], "debug": 51, "deepseek": 53, "deepseek_cod": 53, "deepseek_mo": 53, "deepspe": [20, 23, 51], "deepspeed_zero1": 51, "def": [36, 50, 52, 54], "default": [22, 37, 53], "defaultsampl": [13, 34], "defin": [36, 50, 52, 54], "demo": 22, "demonstr": 22, "denot": [53, 54], "depend": 14, "depth": 48, "describ": [22, 50, 54], "descript": [22, 54], "design": 22, "desir": 13, "detail": [13, 15, 21, 31, 34, 35, 37, 48, 51, 54], "dev": 46, "dialogu": [50, 53], "dict": [13, 15, 22, 34, 36, 37, 50, 52, 53, 54], "didn": 52, "diet": 47, "differ": [13, 14, 34, 35, 36, 50, 52, 54], "difficult": 34, "dir": [22, 51], "direct": [13, 14, 15, 35], "directli": [14, 22], "directori": [15, 22, 37, 48, 50, 51, 52, 54], "discard": 52, "distinct": 54, "distribut": 51, "dlc": 51, "do": [14, 22, 36, 47, 48, 52], "document": [50, 51, 52, 54], "dodger": 36, "doe": [47, 50, 52, 54], "doesn": 50, "domain": [47, 50], "don": [36, 46, 49], "done": [22, 48], "doubl": 22, "download": [15, 35, 37, 48], "downloaded_data": 48, "downsid": 47, "downstream": 47, "dpo": [35, 36], "dpo_loss_typ": 13, "due": [14, 22, 35], "dure": [14, 23, 35, 50, 51, 53, 54], "e": [20, 53], "each": [22, 36, 47, 53], "eas": 47, "easi": 34, "eat": 47, "echo": 51, "edit": 20, "ee0000": 22, "effect": [14, 20, 35], "effici": [14, 35, 47], "either": 22, "elabor": 53, "element": 22, "elif": 52, "elimin": 14, "els": [13, 34, 36, 52, 54], "elucid": 47, "emot": 36, "emotion": 36, "empti": 47, "enabl": [13, 34], "end": [22, 34, 36, 47, 53], "english": 47, "enhanc": [14, 35, 47, 50, 52, 54], "enligsh": 22, "enough": 47, "ensur": [36, 53, 54], "enter": 22, "entir": 47, "env": 20, "environ": 20, "enzh": [46, 49], "eo": 53, "eoa": 53, "eoh": 53, "eos_token": 53, "epoch": 22, "eta": [22, 37], "etc": 13, "evalu": 35, "evaluatechathook": [22, 50], "evaluation_freq": 50, "evaluation_input": 50, "every_n_it": 50, "exampl": [14, 15, 22, 34, 36, 37, 47, 48, 50, 52, 53, 54], "execut": [15, 22, 37, 50, 52, 54], "exercis": [36, 47], "exit": 22, "exp_nam": 51, "experienc": 22, "explain": [50, 52], "explan": [22, 34], "export": 46, "express": 47, "extens": 48, "extrem": 23, "f": [48, 54], "face": [13, 34, 36], "fairli": 22, "fall": 22, "fals": [13, 15, 22, 34, 37, 53], "fanqino1": 22, "featur": [23, 50, 52, 54], "feed": 47, "feedback": [35, 37], "few": 22, "fi": 48, "field": [13, 22, 34, 36, 47, 53], "figur": 47, "file": [13, 20, 22, 23, 34, 36], "fill": 36, "filter": 35, "find": 48, "fine": [23, 31, 35, 37, 47, 52, 54], "finetun": [47, 50, 52, 54], "first": [22, 46, 49, 53], "fit": 35, "flash": [14, 23, 35], "flow": 36, "fluoresc": 22, "fnlp": 48, "focal": 34, "follow": [14, 15, 20, 22, 35, 36, 37, 47, 50, 51, 52, 54], "forget": [46, 49], "fork": 23, "form": [47, 48], "format": [15, 22, 34, 36, 37, 48], "four": [36, 54], "framework": 21, "fresh": [22, 36], "from": [13, 14, 15, 20, 34, 35, 36, 37, 46, 47, 48, 50, 52, 54], "ftdp": 23, "full": 35, "fulli": [22, 47], "function": [14, 23, 35, 36, 50, 52, 54], "further": 31, "fuzzi": [50, 52, 54], "game": 36, "gameplai": 31, "gemma": 53, "gener": [14, 35, 47, 53], "generation_config": 22, "gentitl": [46, 49], "get": [15, 22, 37, 46, 47, 48, 54], "git": [20, 22, 48], "github": [20, 48], "give": [22, 47], "given": 35, "globe": 36, "go": 47, "goal": 47, "good": 35, "googl": [46, 48, 53], "gpt": 48, "gpu": [15, 22, 31, 37], "gpu_num": [15, 22, 37], "gqa": 48, "grad_norm": 22, "grade": 31, "gradient": 47, "grate": 36, "great": 36, "green": [22, 36], "grill": 36, "groundtruth": [47, 54], "group": 23, "grown": 36, "guanaco": [50, 52], "guid": [14, 23, 35], "ha": [22, 36, 48, 50, 52, 53], "handl": [13, 14, 34, 35], "hardwar": [14, 35], "have": [14, 22, 34, 47, 48, 50, 54], "head": 35, "healthi": 47, "hello": 47, "help": [15, 22, 35, 36, 37, 47], "here": [15, 22, 36, 37, 46, 49], "hexadecim": 22, "hf": [22, 35, 37, 46, 53], "highest": 35, "highli": 54, "hing": 13, "hint": 22, "histori": 22, "horseradish": 36, "how": [13, 15, 20, 22, 34, 36, 37, 46, 47, 49, 50, 51, 52, 54], "http": [15, 20, 22, 37, 46, 48], "hub": 48, "hug": [13, 34, 36], "huggingfac": [15, 31, 37, 46, 49], "huggingface_hub": 22, "huggingfaceh4": 53, "huggyllama": 53, "human": [14, 15, 22, 35, 37, 47, 52], "hyperparamet": 23, "i": [14, 20, 22, 23, 31, 34, 35, 36, 37, 47, 48, 50, 51, 52, 53, 54], "id": 34, "idea": 36, "ident": 14, "ignor": 52, "illustr": 52, "im_end": [22, 53], "im_start": [22, 53], "imag": [36, 48], "implement": [14, 34, 50, 52, 54], "import": [22, 36, 50, 52, 54], "improv": [14, 35, 47], "inc": 53, "includ": [31, 35, 47, 54], "increment": 52, "index": 22, "indic": [20, 47], "infer": 35, "info": [22, 37, 51], "inform": [13, 14, 34, 35, 47, 53], "initi": [15, 37], "input": [22, 35, 46, 47, 49, 50, 52, 53, 54], "instal": [22, 23, 48], "instanc": [47, 48], "instead": [22, 36], "instruct": [15, 34, 37, 47, 48, 50, 51, 52, 53, 54], "integr": [15, 20, 22, 35, 37], "intel": 36, "intel_orca_dpo_map_fn": 36, "intellig": 47, "intend": 47, "interest": 36, "interfac": 51, "internlm": [13, 15, 20, 22, 34, 37, 50, 51, 52, 53, 54], "internlm2": [13, 15, 22, 34, 35, 37, 53], "internlm2_7b": 22, "internlm2_7b_qlora_colorist_e5": 22, "internlm2_7b_qlora_colorist_e5_copi": 22, "internlm2_chat": [22, 53], "internlm2_chat_1_8b_dpo_ful": 15, "internlm2_chat_1_8b_dpo_full_copi": 15, "internlm2_chat_1_8b_reward_full_ultrafeedback": 37, "internlm2_chat_1_8b_reward_full_ultrafeedback_copi": 37, "internlm2forrewardmodel": 37, "internlm_7b_full_intern_repo_dataset_templ": 51, "internlm_7b_full_intern_repo_dataset_template_copi": 51, "internlm_7b_qlora_alpaca_e3": 54, "internlm_7b_qlora_alpaca_enzh_e3": 49, "internlm_7b_qlora_arxiv_gentitle_e3": 49, "internlm_7b_qlora_code_alpaca_e3": 49, "internlm_7b_qlora_colorist_e5": 49, "internlm_7b_qlora_lawyer_e3": 49, "internlm_7b_qlora_oasst1_e3": [49, 50, 52], "internlm_7b_qlora_open_platypus_e3": 49, "internlm_7b_qlora_sql_e3": 49, "internlm_chat": [46, 50, 53], "introduc": [13, 15, 21, 34, 37, 47, 52, 54], "introduct": [23, 47], "involv": [47, 51], "ipo": [13, 14], "is_dpo": [13, 15, 34, 36, 37], "is_reward": [13, 15, 34, 36, 37], "issu": 22, "iter": [22, 37], "iter_15230": [15, 37], "iter_15230_hf": [15, 37], "iter_720": 22, "iter_720_hf": 22, "its": [22, 47, 53], "itself": [35, 51], "jpg": 48, "json": [22, 36, 48, 50, 52, 54], "jsonl": [22, 36, 48], "just": 22, "kaggl": 48, "keep": 48, "kei": [46, 47], "know": 36, "knowledg": [47, 52], "kto_pair": 13, "kubernetes_container_resource_gpu": 51, "l2": 34, "lab": 54, "label": [13, 36], "label_smooth": 13, "laboratori": 47, "lagent": 46, "languag": [14, 35, 37, 47, 52], "larg": [14, 23, 35, 47], "larger": [14, 35], "last": 52, "latest": [14, 35], "launch": 51, "launcher": [15, 22, 37, 51], "law": 48, "lawyer": 49, "lead": [22, 47], "learn": [14, 35, 36, 46, 47, 49, 52], "left": 47, "len": 52, "length": [13, 14, 23, 34, 35, 47], "leverag": [14, 35], "lf": 48, "librari": 37, "life": 36, "light": 22, "like": [14, 22, 36, 37, 53], "limit": 35, "line": [20, 36], "link": [15, 21, 22, 37, 48], "list": [15, 20, 22, 37, 47], "littl": 36, "liuhaotian": 48, "liuhc0428": 48, "llama": [34, 53], "llama2_7b_qlora_arxiv_gentitle_e3": 49, "llama2_7b_qlora_colorist_e5": 49, "llama2_7b_qlora_moss_sft_all_e1": 49, "llama2_7b_qlora_moss_sft_all_e2_gpu8": 49, "llama2_chat": 53, "llama3": [34, 37], "llamaforsequenceclassif": 37, "llava_data": 48, "llava_imag": 48, "llava_v1_5_mix665k": 48, "llm": [22, 23, 31, 53], "lmdeploi": 23, "lmsy": 53, "lo": 36, "load": [13, 22, 34, 36], "load_dataset": [13, 15, 22, 34, 36, 37, 50, 52, 54], "load_jsonl_dataset": 36, "local": [20, 22], "locat": 22, "log": [22, 34, 37, 50], "log_barri": 34, "logic": 53, "login": [46, 49], "logit": 36, "long": [14, 23, 35], "look": [22, 37], "lora": [14, 23], "loss": [14, 22, 23, 35, 36, 37, 47, 51, 52], "loss_beta": 13, "loss_typ": 34, "low": 47, "lr": [22, 37], "m": 51, "machin": 15, "made": [14, 50], "mai": 22, "main": [50, 52, 54], "mainstream": 47, "maintain": [34, 36, 47], "make": [14, 48, 50, 52, 54], "mani": [13, 14, 31, 34, 47], "manual": [15, 35, 37, 53], "map": [13, 34, 36], "map_fn": [36, 50, 52, 54], "mask": 36, "master_addr": 51, "master_port": 51, "match": 22, "matur": 36, "max": [22, 23], "max_length": [13, 22, 34, 36, 50, 51, 52, 54], "max_packed_length": [13, 34], "max_split_size_mb": 51, "maximum": [13, 22, 34], "mayb": 36, "mayonnais": 36, "md": [22, 48], "me": [22, 36], "mean": 36, "mechan": [13, 34], "meet": [50, 52, 54], "memori": [13, 14, 22, 31, 34, 35, 37], "merg": 23, "messag": 36, "meta": [34, 46, 53], "method": [13, 14, 22, 34, 36], "minimum": [31, 54], "mistral": 53, "mistralai": 53, "mix": [13, 15, 22], "mixtral": 53, "mkdir": [15, 22, 37], "mlabonn": [13, 15], "mlx5": 51, "mmbench": 23, "mmengin": [22, 37, 50, 52, 54], "mmlu": 23, "modal": 23, "mode": 20, "model": [14, 36, 47, 51, 53], "modeling_internlm2": 22, "modelscop": [15, 35, 37], "moder": 47, "modif": [15, 20, 37, 50], "modifi": [14, 15, 23, 35, 37, 48], "moe": 53, "mondai": 47, "more": [13, 14, 15, 31, 34, 35, 36, 37, 47, 48], "moss": [46, 49], "moss_sft": 46, "most": 47, "move": 48, "msagent": 46, "multi": [23, 53], "multi_turn_convers": 48, "multipl": [15, 22, 35, 36, 37, 47], "my": [36, 47], "n": [35, 47, 53, 54], "name": [20, 22, 46, 47, 48, 51], "natur": 47, "nca_pair": 13, "nccl_buffsiz": 51, "nccl_debug": 51, "nccl_ib_gid_index": 51, "nccl_ib_hca": 51, "nccl_ib_qps_per_connect": 51, "nccl_ib_sl": 51, "nccl_ib_tc": 51, "nccl_ib_timeout": 51, "nccl_net_plugin": 51, "nccl_socket_ifnam": 51, "necessari": [50, 54], "need": [13, 14, 15, 22, 34, 36, 37, 47, 50, 51, 52, 53, 54], "neg": 51, "network": 22, "nice": 36, "nnode": 51, "node": 37, "node_rank": 51, "none": [50, 51, 52, 54], "noon": 47, "nooutput": 54, "note": [34, 37, 47, 51, 53], "notic": 36, "nproc_per_nod": [15, 22, 37, 49, 51], "nth": 47, "num_proc": [13, 34], "num_row": [50, 52, 54], "num_sampl": 37, "num_token": 37, "num_work": [13, 34], "number": [13, 34], "numer": 35, "oasst1": [46, 49, 50, 52], "oasst1_incremental_map_fn": 50, "oasst1_map_fn": [50, 52], "obtain": [46, 49, 50], "ocr": 48, "ocr_vqa": 48, "ocr_vqa_path": 48, "odd": 14, "offer": [14, 35, 52, 54], "offici": [37, 53], "often": [22, 47], "onc": [22, 53], "one": [22, 47], "ones": 20, "onion": 36, "onli": [14, 31, 35, 36, 37, 47, 50, 51, 52, 53], "open": [15, 23, 37, 49], "openai": 36, "openassist": [50, 52], "opencompass": 23, "openxlab": 35, "oper": [50, 52, 54], "optim": [13, 14, 15, 35], "option": [13, 48], "orca_dpo_pair": 36, "organ": 54, "origin": [22, 36], "orpo": [13, 14, 15, 36], "orpo_dpo_mix_40k": 34, "orpo_dpo_mix_40k_map_fn": [13, 15, 34, 37], "other": [15, 22, 36, 37, 50, 52], "otherwis": 53, "our": [20, 47], "out": 22, "output": [22, 34, 35, 36, 47, 50, 52, 53, 54], "overfit": [34, 35], "overhead": [14, 35], "overview": 23, "p": [48, 50, 52, 54], "pack": [14, 23, 35], "pack_to_max_length": [22, 50, 51, 52, 54], "pad": [13, 14, 34, 35], "pair": [14, 35, 47], "palett": 22, "paper": [14, 37, 48], "parallel": [14, 35, 47], "paramet": [13, 14, 15, 22, 35, 37], "part": [13, 22, 34, 36, 47, 50, 51, 52, 54], "part1": 48, "part2": 48, "particip": 47, "path": [13, 15, 22, 34, 36, 37, 48, 50, 51, 52, 54], "penal": 14, "penalty_typ": 34, "perform": [35, 47], "period": 50, "phase": [47, 53], "pickl": 36, "piec": 47, "pip": [20, 22], "pipelin": 31, "place": 48, "plai": 36, "plan": 47, "platypu": 49, "pleas": [13, 14, 15, 22, 31, 34, 35, 37, 46, 48, 50, 52, 54], "plugin": [31, 46, 49], "point": 22, "polici": [14, 35], "pop": 52, "posit": 47, "possibl": 47, "ppo": 35, "practic": [23, 36, 47], "pre": [15, 37, 51, 52, 53], "predict": [35, 47], "prefer": [13, 14, 15, 23, 34, 35, 37], "preference_collate_fn": [13, 34], "prepar": 36, "preprocess": [37, 47, 48, 52, 54], "prescrib": 54, "present": 54, "pretrain": [13, 23, 34], "pretrained_model_name_or_path": [13, 15, 22, 34, 37, 51], "primari": [35, 51], "print": 20, "problem": [22, 54], "process": [14, 15, 22, 23, 35, 36, 37, 47, 48, 50, 51, 52, 54], "process_hf_dataset": [22, 50, 52, 54], "profession": 22, "program": 47, "project": 20, "prompt": [22, 23, 35, 36, 46], "prompt_templ": [22, 50, 52, 54], "propos": 34, "provid": [13, 14, 15, 21, 22, 35, 37, 47, 50, 51, 52, 54], "proxi": 35, "proxim": 35, "pth": [15, 22, 37], "pth_to_hf": [15, 22, 37], "pull": 22, "purpos": [47, 52], "puyu": 47, "py": [15, 22, 37, 50, 51, 52, 54], "python": [20, 22, 51], "pythonpath": 51, "pytorch": 51, "pytorch_cuda_alloc_conf": 51, "pytorch_model": 22, "q": 53, "qlora": [14, 22, 35, 46], "qualiti": [14, 35], "question": [36, 47], "quick": [14, 23, 35], "quickli": [15, 22, 37, 48], "quickstart": 23, "qwen": 53, "qwen1": 53, "qwen_7b_qlora_alpaca_enzh_e3": 49, "qwen_7b_qlora_arxiv_gentitle_e3": 49, "qwen_7b_qlora_moss_sft_all_e1": 49, "qwen_7b_qlora_moss_sft_all_e2_gpu8": 49, "qwen_7b_qlora_oasst1_e3": 49, "qwen_chat": 53, "r": 52, "rain": 47, "rang": [35, 52], "rank": [34, 51], "rate": 47, "rather": 51, "ratio": 14, "raw": 48, "re": 22, "react": 46, "read": [22, 48], "read_bas": [50, 52, 54], "readi": [15, 37, 50, 52, 54], "readm": 22, "real": [36, 51], "reason": 22, "recommend": [13, 20, 34, 36, 49, 50, 52, 54], "record": 54, "red": 22, "reduc": [14, 35, 47, 54], "ref": 48, "refcoco_ann_path": 48, "refcoco_annot": 48, "refcocog": 48, "refcocojson": 48, "refer": [13, 14, 15, 22, 34, 35, 37, 48, 50, 52, 54], "regul": 36, "regularli": 47, "reinforc": [14, 35], "reinstal": 20, "reject": [13, 14, 34, 35, 36], "rejected_score_mean": 37, "relat": [13, 34, 50, 52, 54], "releas": [31, 48], "reli": 14, "reminisc": 22, "remov": 14, "remove_unused_column": [22, 50, 52, 54], "renam": 48, "replac": [35, 50, 52, 53, 54], "report": [34, 35], "repositori": 51, "repres": [50, 52, 53, 54], "request": 54, "requir": [14, 22, 31, 47, 54], "resembl": 22, "reserved_special_token_0": 34, "reset": 22, "respect": 34, "respond": [47, 54], "respons": [35, 36, 47, 53, 54], "result": 35, "resum": 22, "return": [36, 50, 52, 54], "reward": [14, 36], "reward_token_id": [13, 34], "rewardbench": 35, "rgb": 22, "ripe": 22, "rlhf": 35, "robust": 13, "role": 36, "rosso": 47, "round": [47, 52, 54], "row": 50, "run": 37, "runtim": 50, "same": [14, 22, 34, 35, 36], "sampl": [13, 14, 22, 34, 35, 36], "sampler": [13, 23, 34], "sandwich": 36, "satur": 22, "save": [22, 36, 47, 48], "save_data_path": 48, "save_dir": [50, 52, 54], "save_path": 48, "scale": 23, "score": [34, 35], "script": [48, 50, 52, 54], "search": [46, 50, 52, 54], "section": [13, 14, 15, 20, 22, 34, 35, 37, 50, 52], "see": [14, 20, 35, 46, 49, 50], "select": [13, 35, 54], "sentenc": [47, 52], "sep": 53, "separ": 53, "sequenc": [13, 14, 23, 34, 35, 53], "sequence_parallel_s": [13, 34], "sequenceclassif": 37, "sequenceparallelsampl": [13, 34], "seri": 36, "serper": 46, "serper_api_kei": 46, "serv": [52, 53], "session": 54, "set": [13, 14, 15, 22, 23, 34, 35, 37, 47, 50, 51, 52, 53, 54], "sever": [15, 22, 31, 37, 47, 50, 52, 54], "sft": [13, 15, 23, 34, 36, 37, 46, 47, 49, 50, 52, 54], "shade": 22, "shanghai": 47, "shanghai_ai_laboratori": [15, 22, 37], "shard": 22, "should": [20, 22, 37, 47, 50, 52, 54], "show": [20, 22, 54], "shown": [22, 36, 47, 50, 54], "shuffl": [13, 34], "shuffle_before_pack": [13, 22, 34, 50, 52, 54], "sigmoid": 13, "signal": 35, "signific": [14, 35], "significantli": [14, 35, 54], "similar": [14, 22, 36], "simpl": [22, 35], "simpli": [15, 37], "simplifi": 14, "simultan": [31, 36], "sinc": [22, 37, 47, 50, 52, 54], "singl": [13, 15, 22, 34, 36, 37, 53], "single_turn_convers": [48, 52], "size": 22, "sky": 22, "sleep": 47, "slice": [22, 36], "slight": 22, "slow": 22, "slurm": [15, 22, 37, 51], "smooth": 13, "snapshot_download": 22, "so": [20, 34], "sole": 52, "solv": 46, "some": [14, 22, 36, 52], "someth": 36, "sorri": 36, "sound": 36, "sourc": [15, 20, 23, 37, 48, 51], "speak": 47, "special": [34, 36, 53], "special_tokens_map": 22, "specif": [22, 36, 47, 50, 53, 54], "specifi": [13, 15, 22, 34, 37, 53], "speed": 22, "split": [47, 52], "sppo_hard": 13, "sql": 49, "srun": [15, 22, 37, 51], "srun_arg": [15, 22, 37, 51], "stabil": 35, "stabl": 34, "stage": [47, 53], "stai": 47, "standard": [14, 22], "star": 23, "starcod": 53, "start": [47, 48], "step": [15, 20, 22, 37, 48], "still": 53, "stop": 53, "stop_word": 53, "store": [22, 37, 50, 52, 54], "strategi": [13, 34, 35], "streamer": 46, "strip": 52, "structur": 22, "studi": 47, "sub": 48, "subsequ": 36, "substanti": 35, "successfulli": 22, "suffix": 53, "suffix_as_eo": 53, "suggest": 22, "summari": [15, 22, 37], "sunni": 22, "supervis": [47, 50, 52, 54], "support": [13, 14, 23, 31, 34, 46, 47, 50, 52, 54], "suppos": [47, 50, 52, 54], "sure": [48, 52], "switch": 34, "symbol": 53, "symlink": 22, "system": [22, 36, 46, 47, 50, 52, 53, 54], "system_alpaca": 54, "system_oasst1": 52, "t": [36, 46, 49, 50, 52], "tailor": 47, "take": [20, 36], "target_dir": 48, "task": [15, 35, 36, 37, 47, 50, 54], "tatsu": 54, "technic": [34, 35], "techniqu": 35, "technologi": 47, "temperatur": 13, "templat": [22, 23, 46, 50, 52, 54], "template_map_fn": [22, 50, 52, 54], "template_map_fn_factori": [22, 50, 52, 54], "term": [34, 36], "terri": 34, "texa": 36, "text": [14, 35, 36, 47, 48, 50, 52, 53, 54], "text2imag": 48, "textvqa": 48, "than": 51, "thank": 47, "them": [13, 22, 34, 36, 47, 48, 50, 51, 52, 54], "therebi": [14, 35], "therefor": [22, 34, 36, 47, 50, 52, 53, 54], "thi": [13, 14, 15, 20, 21, 22, 34, 35, 36, 37, 47, 48, 50, 51, 52, 53, 54], "thing": 36, "three": [36, 47, 54], "through": [36, 47, 50, 54], "throughout": 47, "thudm": 53, "timdettm": [50, 52], "time": [22, 37, 54], "tip": 47, "todai": 47, "togeth": 47, "token": [13, 14, 22, 34, 35, 36, 46, 47, 49, 50, 51, 52, 53, 54], "tokenization_internlm2": 22, "tokenization_internlm2_fast": 22, "tokenizer_config": 22, "tomato": 36, "tool": [15, 22, 37, 48, 50, 51, 52, 54], "toolbox": 23, "top": 36, "torch": 51, "tradit": 14, "train": [22, 31, 48, 49, 52, 53, 54], "train2017": 48, "train_d": 50, "train_dataload": [13, 34], "train_dataset": [13, 15, 22, 34, 36, 37, 50, 52, 54], "train_imag": 48, "train_val_imag": 48, "tranquil": 22, "transform": [35, 37, 52], "tropic": 22, "true": [13, 15, 22, 34, 37, 50, 51, 52, 53, 54], "truncat": [13, 34], "try": 36, "tune": [23, 31, 35, 37, 47, 52, 54], "turn": 53, "turquois": 22, "tutori": [14, 15, 21, 37], "two": [22, 47, 48], "type": [13, 15, 22, 34, 36, 37, 47, 48, 50, 52, 54], "typic": [35, 47, 53], "u": [20, 22], "ultrafeedback": [34, 37], "unc": 48, "und": 48, "under": [14, 15, 35, 37], "understand": [14, 35, 36, 52], "unifi": 47, "uniform": [36, 47], "univers": 48, "unlik": 14, "unstabl": 22, "unus": 34, "unused_token_130": 34, "unzip": 48, "updat": [22, 47], "us": [13, 14, 15, 20, 22, 34, 35, 36, 37, 46, 47, 48, 49, 51, 53], "use_varlen_attn": [13, 34, 51], "user": [13, 14, 20, 22, 34, 35, 36, 47, 50, 52, 53, 54], "user1": 47, "user2": 47, "user3": 47, "usern": 47, "usual": 34, "util": [14, 35, 47, 48, 53, 54], "v0": 53, "v1": 53, "valid": 48, "valu": [35, 36, 47, 51], "vari": 52, "variabl": [13, 14, 34, 35], "variou": [13, 31, 47], "varlen": 23, "veri": [14, 22], "verifi": [23, 50, 52, 54], "vg": 48, "vg_100k": 48, "vg_100k_2": 48, "via": [20, 22], "vibrant": 22, "vicuna": 53, "view": [15, 22, 37, 47, 50, 52, 54], "virtual": 20, "visit": 31, "visual": 23, "visualgenom": 48, "vivid": 22, "vlm": 23, "vocabulari": [34, 47], "vqa": 48, "wa": [36, 47, 54], "wai": 36, "want": [15, 37, 50, 52, 54], "wast": [13, 14, 34, 35], "watch": 23, "water": 22, "we": [13, 14, 15, 20, 22, 34, 35, 36, 37, 47, 48, 50, 52, 53, 54], "weather": 47, "wednesdai": 47, "weight": [14, 23, 34, 47], "welcom": [35, 47], "were": 53, "what": [23, 36, 47], "when": [13, 15, 22, 34, 36, 37, 47, 50, 52, 54], "where": [22, 36, 53], "wherea": 47, "whether": 53, "which": [15, 22, 34, 35, 37, 47, 53], "while": [35, 47, 48, 54], "who": 36, "within": [13, 34], "without": [20, 52, 53], "won": 36, "word": 53, "work": [51, 54], "work_dir": [15, 22, 37, 51], "workflow": 21, "world": 36, "world_siz": 51, "worth": 53, "write": [13, 34, 54], "www": 22, "xtuner": [13, 15, 20, 22, 31, 34, 36, 37, 46, 48, 49, 50, 51, 52, 53, 54], "xxx": [46, 47, 50, 52, 54], "y": 20, "yet": 47, "yi": 53, "you": [13, 15, 20, 21, 22, 34, 36, 37, 47, 48, 50, 51, 52, 54], "your": [13, 15, 36, 37, 46, 48, 49, 50, 51, 52, 54], "your_exp_nam": 51, "zephyr": 53, "zip": 48, "\u4e00\u79cd\u4ecb\u4e8e\u5929\u84dd\u548c\u5a74\u513f\u84dd\u4e4b\u95f4\u7684\u5e73\u548c": 22, "\u4e0d\u542b\u4efb\u4f55\u84dd\u8272\u6216\u7eff\u8272\u5143\u7d20": 22, "\u4e3a\u4e86\u5339\u914d\u60a8\u6240\u63cf\u8ff0\u7684": 22, "\u50cf\u5929\u7a7a\u4e00\u6837\u6e05\u6f88\u900f\u660e\u7684\u84dd\u8272": 22, "\u5448\u73b0\u51fa\u4e00\u79cd\u5145\u6ee1\u6d3b\u529b\u7684\u7eff\u677e\u77f3\u8272\u8c03": 22, "\u5929\u7a7a\u4e00\u6837\u6e05\u6f88\u900f\u660e\u7684\u84dd\u8272": 22, "\u5929\u84dd": 22, "\u5b83\u5177\u6709\u660e\u4eae": 22, "\u5b83\u662f\u6807\u51c6": 22, "\u5b83\u8ba9\u4eba\u8054\u60f3\u5230\u70ed\u5e26\u6c34\u57df": 22, "\u6211\u5efa\u8bae\u60a8\u9009\u62e9\u4e00\u79cd\u540d\u4e3a": 22, "\u660e\u4eae\u7684\u7eff\u677e\u77f3\u8272": 22, "\u6d45\u5929\u84dd\u8272": 22, "\u6d77\u6d0b\u548c\u6e05\u6f88\u7684\u6c34\u57df": 22, "\u751f\u52a8\u7684\u7ea2\u8272": 22, "\u7531\u4e8e\u660e\u4eae\u800c\u5e26\u6709\u4e00\u4e1d\u8f7b\u5fae\u7684\u8367\u5149": 22, "\u7684\u989c\u8272": 22, "\u76f8\u5f53\u660e\u4eae\u7684\u989c\u8272": 22, "\u7c7b\u4f3c\u6210\u719f\u82f9\u679c\u6216\u65b0\u9c9c\u8840\u6db2\u7684\u989c\u8272": 22, "\u8bad\u7ec3\u6570\u636e_\u5e26\u6cd5\u5f8b\u4f9d\u636e_92k": 48, "\u8bf7\u7ed9\u6211\u4e00\u4e2a\u50cf\u5929\u7a7a\u4e00\u6837\u6e05\u6f88\u900f\u660e\u7684\u84dd\u8272": 22, "\u8c03\u8272\u677f\u4e0a\u7684\u7ea2\u8272": 22, "\u8fd9\u662f\u4e00\u79cd\u975e\u5e38\u9c9c\u8273": 22, "\u8fd9\u79cd\u989c\u8272\u878d\u5408\u4e86\u9c9c\u7eff\u8272\u7684\u6e05\u65b0\u548c\u6de1\u84dd\u8272\u7684\u5b81\u9759": 22, "\u8fd9\u79cd\u989c\u8272\u901a\u5e38\u88ab\u7528\u6765\u4ee3\u8868\u5929\u7a7a": 22, "\u9971\u548c": 22, "\u9c9c\u7ea2\u8272": 22}, "titles": ["Benchmark", "DeepSpeed", "Flash Attention", "HyperParameters", "Length Grouped Sampler", "Pack to Max Length", "Train Extreme Long Sequence", "Train Large-scale Dataset", "Varlen Flash Attention", "Chat with Agent", "Chat with LLM", "Accelerate chat by LMDeploy", "Chat with VLM", "Modify DPO Training Configuration", "Introduction to DPO", "Quick Start with DPO", "Evaluation during training", "MMBench (VLM)", "MMLU (LLM)", "Evaluate with OpenCompass", "Installation", "Overview", "Quickstart", "Welcome to XTuner\u2019s documentation!", "Case 1", "Case 2", "Case 3", "Case 4", "ftdp", "InternEVO Migration", "Supported Models", "Changelog", "Pretrained Model", "Prompt Template", "Modify Reward Model Training Configuration", "Introduction to Reward Model", "Preference Dataset", "Quick Start Guide for Reward Model", "<a href='https://xtuner.readthedocs.io/en/latest/'>English</a>", "Custom Agent Dataset", "Custom Pretrain Dataset", "Custom SFT Dataset", "Modify Settings", "Multi-modal Dataset", "Open Source Datasets", "Visualization", "Chat with fine-tuned LLMs", "Dataset Format", "Dataset Prepare", "Fine-tune the pretrained LLMs", "Incremental Pre-training Data Pipeline", "Tutorial", "Multi-turn Dialogue Data Pipeline", "Prompt Template", "Single-turn Dialogue Data Pipeline"], "titleterms": {"": 23, "0": 31, "003": 48, "08": 31, "1": [24, 31, 47, 50, 51, 52, 54], "2": [25, 46, 47, 50, 51, 52, 54], "2023": 31, "20b": 46, "3": [26, 50, 51, 52, 54], "30": 31, "4": [27, 50, 52, 54], "5": [50, 52, 54], "7b": 46, "acceler": [11, 13, 23, 34], "agent": [9, 39], "alpaca": 54, "arxiv": 48, "attent": [2, 8], "baichuan": 49, "benchmark": 0, "best": 20, "candid": [50, 52, 54], "case": [24, 25, 26, 27], "changelog": 31, "chat": [9, 10, 11, 12, 22, 23, 46], "check": [50, 52, 54], "chines": 48, "choos": 53, "config": [22, 50, 51, 52, 54], "configur": [13, 15, 34, 37], "convers": [15, 37], "convert": 22, "custom": [36, 39, 40, 41, 50, 52, 54], "data": [13, 15, 34, 36, 37, 50, 52, 54], "dataset": [7, 22, 36, 39, 40, 41, 43, 44, 47, 48, 50, 51, 52, 54], "deepspe": 1, "dialogu": [47, 52, 54], "document": 23, "download": 22, "dpo": [13, 14, 15, 23], "dure": 16, "en": 38, "english": 38, "evalu": [16, 19, 23], "export": [50, 51, 52, 54], "extrem": 6, "featur": [14, 35], "file": [15, 37, 48, 50, 51, 52, 54], "fine": [22, 46, 49], "finetun": 48, "flash": [2, 8], "format": [47, 50, 51, 52, 54], "from": 22, "ftdp": 28, "function": [13, 34], "gentitl": 48, "get": [14, 23, 35], "group": 4, "guid": 37, "highlight": 31, "href": 38, "http": 38, "hub": [50, 52, 54], "huggingfac": [22, 48, 50, 52, 54], "hyperparamet": 3, "i": 21, "increment": [47, 50], "instal": 20, "internevo": [23, 29], "internlm": [46, 49], "introduct": [14, 35], "io": 38, "larg": 7, "latest": 38, "lawyer": 48, "length": [4, 5], "list": [50, 52, 54], "llama": 46, "llama2": [46, 49], "llava": 48, "llm": [10, 18, 46, 49], "lmdeploi": 11, "long": 6, "lora": 22, "loss": [13, 34], "map": [50, 52, 54], "max": 5, "merg": 22, "method": 47, "migrat": [23, 29], "mmbench": 17, "mmlu": 18, "modal": 43, "model": [13, 15, 22, 23, 30, 32, 34, 35, 37, 50, 52, 54], "modelscop": 22, "modifi": [13, 22, 34, 42, 50, 51, 52, 54], "moss": 48, "multi": [43, 47, 52], "name": [50, 52, 54], "open": [35, 36, 44], "opencompass": 19, "option": [50, 52, 54], "origin": [50, 52, 54], "other": [48, 54], "overview": [14, 21, 35, 36], "pack": 5, "pipelin": [50, 52, 54], "practic": 20, "pre": [47, 50], "prefer": 36, "prepar": [15, 22, 23, 37, 48, 50, 52, 54], "pretrain": [15, 32, 37, 40, 48, 49], "process": 20, "prompt": [33, 53], "qlora": 49, "quick": [15, 37], "quickstart": 22, "qwen": [46, 49], "readthedoc": 38, "refcoco": 48, "result": 53, "reward": [23, 34, 35, 37], "sampler": 4, "scale": 7, "sequenc": 6, "set": 42, "sft": [41, 48], "singl": [47, 54], "sourc": [35, 36, 44], "standard": [50, 52, 54], "start": [14, 15, 22, 23, 35, 37, 51], "step": [50, 51, 52, 54], "structur": [48, 53], "support": 30, "templat": [33, 51, 53], "train": [6, 7, 13, 14, 15, 16, 23, 34, 35, 36, 37, 47, 50, 51], "tune": [22, 46, 49], "turn": [47, 52, 54], "tutori": 51, "us": [50, 52, 54], "v0": 31, "varlen": 8, "verifi": 20, "visual": 45, "vlm": [12, 17], "weight": [15, 22, 37], "welcom": 23, "what": 21, "xtuner": [14, 21, 23, 35, 38, 47], "zh_cn": 38, "\u7b80\u4f53\u4e2d\u6587": 38}})
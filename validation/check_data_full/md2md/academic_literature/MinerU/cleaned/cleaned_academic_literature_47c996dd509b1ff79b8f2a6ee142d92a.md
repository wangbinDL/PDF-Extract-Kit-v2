# THE LOCAL TO UNITY DYNAMIC TOBIT MODEL  

ANNA BYKHOVSKAYA AND JAMES A. DUFFY  

Abstract.  This paper considers highly persistent time series that are subject to nonlin- earities in the form of censoring or an occasionally binding constraint, such as are regularly encountered in macroeconomics. A tractable candidate model for such series is the dynamic Tobit with a root local to unity. We show that this model generates a process that converges weakly to a non-standard limiting process, that is constrained (regulated) to be positive, and derive the limiting distributions of the OLS estimators of the model parameters. This allows inferences to be drawn on the overall persistence of the process (as measured by the sum of the autoregressive coeﬃcients), and for the null of a unit root to be tested in the presence of censoring. Our simulations illustrate that the conventional ADF test substantially over-rejects when the data is generated by a dynamic Tobit with a unit root. We provide an application of our methods to testing for a unit root in the Swiss franc / euro exchange rate, during a period when this was subject to an occasionally binding lower bound.  

Keywords:  non-negative time series, dynamic Tobit, local unit root, unit root test.  

# 1. Introduction  

Since the 1950s nonlinear models have played an increasingly prominent role in the analysis and prediction of time series data. In many cases, as was noted in early work by Moran (1953), linear models are unable to adequately match the features of observed time series. The eﬀorts to develop models that enjoy the ﬂexibility aﬀorded by nonlinearities, while retaining the tractability of linear models, have subsequently engendered an enormous literature (see e.g. Fan and Yao, 2003; Gao, 2007; Chan, 2009; and Terasvirta  et al. , 2010).  

An important instance of non-linearity arises when data is bounded by, truncated at, or censored below some threshold, since such phenomena cannot be adequately captured – even approximately – by a linear model. Many observed series are bounded below by construction, and may spend lengthy periods at or near their lower boundary, such as unemployment rates, prices, gross sectoral trade ﬂows, and nominal interest rates. The non-negativity of interest rates, and the resulting constraints that this may impose on the eﬃcacy of monetary policy, has received particular attention in recent years, as central bank policy rates have remained at or near the zero lower bound for a signiﬁcant portion of the past two decades, across many economies (see e.g. Mavroeidis, 2021, and the works cited therein).  

A tractable model for such series, which generates both their characteristic serial dependence and censoring, is the dynamic Tobit model. In its static formulation, the model originates with Tobin (1958). In its dynamic formulation, the model typically comes in one of two varieties, which we refer to as the  latent  and  censored  models. In the latent dynamic Tobit, an unobserved process    $\{y_{t}^{*}\}$    }  follows a linear autoregression, with    $y_{t}=\operatorname*{max}\{y_{t}^{*},0\}$  }  being observed; whereas in the censored dynamic Tobit,    $\{y_{t}\}$   is modelled as the positive part of a linear function of its own lags, and an additive error (see e.g. Maddala 1983, p. 186, or Wei 1999, p. 419). In both models the right hand side may be augmented with other explanatory variables. Relative to the latent model, the censored model has the advantage of being Markovian, which greatly facilitates its use in forecasting. It has also been successfully applied to a range of censored series, in both purely time series and panel data settings, including: the open market operations of the Federal Reserve (Demiralp and Jord\` a, 2002; de Jong and Herrera, 2011); household commodity purchases (Dong  et al. , 2012); loan charge-oﬀrates (Liu  et al. , 2019); credit default and overdue loan repayments (Brezigar-Masten  et al. , 2021); and sectoral bilateral trade ﬂows (Bykhovskaya, 2023). Recently, Mavroeidis (2021) proposed the censored and kinked structural VAR model to describe the operation of monetary policy during periods when the zero lower bound may occasionally bind on the policy rate. If only the actual interest rate (rather than some ‘shadow rate’) aﬀects agents’ decision making, as assumed in closely related work by Aruoba  et al.  (2022), then the univariate counterpart of this model is exactly the censored dynamic Tobit.  

The present work is concerned with the censored, rather than the latent, dynamic Tobit model. In the latent model the dynamics are simply those of the latent autoregression, and so are readily understood; whereas in the censored model, the censoring aﬀects the dynamics of  $\{y_{t}\}$   in a non-trivial manner, making the analysis rather more challenging. Indeed, establishing the stationarity or weak dependence of the censored dynamic Tobit is far from trivial, as can be seen from Hahn and Kuersteiner (2010), de Jong and Herrera (2011), Michel and de Jong (2018), and Bykhovskaya (2023). Henceforth, all references to the ‘dynamic Tobit’ are to the censored version of the model.  

Motivated in part by recent work on modelling nominal interest rates near the zero lower bound, our concern is with the application of this model to series that are highly persistent, so that above the censoring point they exhibit the random wandering that is characteristic of integrated processes. The appropriate conﬁguration of the dynamic Tobit model for such series, in which the autoregressive polynomial has a root local to unity, has not been considered in the literature to date – apart from the special case of a ﬁrst-order model with an exact unit root, as in Cavaliere (2004) and Bykhovskaya (2023). Our results are thus entirely new to the literature.  

Our principal technical contribution, within this setting, is to derive the limiting distri- butions of both the standardised regressor process, and the ordinary least squares (OLS) estimates of the parameters of the dynamic Tobit, when that model has an autoregressive root local to unity. In this setting, OLS is consistent and we obtain a usable limit theory for the estimated sum of the autoregressive coeﬃcients, which conventionally provides a measure of the overall persistence of a process (cf. Andrews and Chen, 1994; Mikusheva, 2007). Our asymptotics provide the basis for practical unit root tests for highly persistent, censored time series. The associated    $t$   statistic coincides with the (constant only) augmented Dickey–Fuller (ADF)    $t$   statistic, but employs critical values modiﬁed to reﬂect the censoring present in the data generating process. We show, via Monte Carlo simulations, that as our critical values are larger than the conventional ADF critical values, their use eliminates the signiﬁcant over- rejection that may result from the naive application of the ADF test to censored data. (This tendency to over-reject the null of a unit root appears typical of models that incorporate unit roots and nonlinearities, having been also found by e.g. Hamori and Tokihisa, 1997; Kim  et al. , 2002; and Wang and De Jong, 2013.)  

Our work may be construed, more broadly, as extending the analysis of highly persistent time series, and the associated machinery of unit root testing, from a linear setting to a nonlinear setting appropriate to time series that are subject to a lower bound. In doing so, we complement the seminal work of Cavaliere (2005), which similarly sought to extend this machinery to the setting of bounded time series. Our contribution is to eﬀect this extension within a class of nonlinear autoregressive models that have been widely applied to censored time series (as evinced by the works cited above), and which fall outside his framework.  

On a technical level, the most closely related works to our own are those of Cavaliere (2004, 2005) and Cavaliere and Xu (2014), who develop the asymptotics of what they term ‘limited autoregressive processes’ with a near-unit root, which are (one- or two-sided) censored pro- cesses constructed by the addition of regulators to a latent linear autoregression. While their (one-sided) model has a superﬁcial resemblance to the dynamic Tobit, there are important, but subtle diﬀerences between the two (see Section 2.4 for a discussion). Perhaps the most striking similarity is that both models, in the case of an exact unit root, give rise to processes that converge weakly to regulated Brownian motion; but when roots are merely local to unity, the limiting processes associated with these two models are distinct (see the discussion fol- lowing Theorem 3.1). Convergence to regulated Brownian motions has also been obtained previously in the setting of  ﬁrst-order  threshold autoregressive models with an (exact) unit root regime and a stationary regime, as considered by Liu  et al.  (2011) and Gao  et al.  (2013).  

The remainder of this paper is organised as follows. Section 2 discusses the model and our assumptions. Asymptotic results and corresponding tests are derived in Section 3, while supporting Monte Carlo simulations are shown in Section 4. Section 5 applies our framework to the exchange rate between the Swiss franc and the euro during a period when this rate was subject to a lower bound. Finally, Section 6 concludes. All proofs appear in the appendices. Notation.    $C$  ,    $C^{\prime}$  ,    $C^{\prime\prime}$  , etc. denote generic constants that may take diﬀerent values in diﬀerent parts of this paper. All limits are taken as    $T\rightarrow\infty$  unless otherwise speciﬁed. → and → respectively denote convergence in probability and distribution (weak convergence). We write  $^{;}X_{T}(r)\ \xrightarrow{d}\ X(r)$  → ) on    $D[0,1]'$   to denote that    $\{X_{T}\}$   converges weakly to    $X$  , where these are considered as random elements of    $D[0,1]$  , the space of cadlag functions on   $[0,1]$  , equipped with the uniform topology. For    $p\geq1$   and    $X$   a random variable, let    $\|X\|_{p}:=(\mathbb{E}|X|^{p})^{1/p}$  .  

# 2. The dynamic Tobit model with a near-unit root  

2.1. Model and assumptions.  Consider a time series    $\{y_{t}\}$   generated by the dynamic Tobit model of order    $k\geq1$  , written in augmented Dickey–Fuller (ADF) form,  

$$
y_{t}=\left[\alpha+\beta y_{t-1}+\sum_{i=1}^{k-1}\phi_{i}\Delta y_{t-i}+u_{t}\right]_{+},\quad t=1,\ldots,T,
$$  

where   $\Delta y_{t}:=y_{t}-y_{t-1}$  , and   $[x]_{+}:=\operatorname*{max}\{x,0\}$   denotes the positive part of    $x\in\mathbb{R}$  . Let  

$$
B(z):=1-\beta z-(1-z)\sum_{i=1}^{k-1}\phi_{i}z^{i}=(1-\beta)z+(1-z)\phi(z),
$$  

where    $\begin{array}{r}{\phi(z):=1-\sum_{i=1}^{k-1}\phi_{i}z^{i}}\end{array}$  . We impose the following on the data generating process (2.1).  

Assumption  A1 .  {  $\{y_{t}\}$  }  is initialised by (possibly) random variables    $\{y_{-k+1},.\.\ .\ ,y_{0}\}$  . Moreover,  $T^{-1/2}y_{0}\stackrel{p}{\rightarrow}b_{0}$  →  for some    $b_{0}\geq0$  .  

Assumption  A2 .    $\{y_{t}\}$   is generated according to  (2.1) , where:  

1.    $\{u_{t}\}_{t\in\mathbb{Z}}$   is independently and identically distributed (i.i.d.) with    $\mathbb{E}u_{t}=0$   and    $\mathbb{E}u_{t}^{2}=\sigma^{2}$  . 2.    $\alpha=\alpha_{T}:=T^{-1/2}a$   and    $\beta=\beta_{T}=\exp(c/T)$   for some    $a,c\in\mathbb{R}$  .  

Assumption  A3 .  There exist    $\delta_{u}>0$   and    $C<\infty$  such that:  

1.    $\mathbb{E}|u_{t}|^{2+\delta_{u}}<C$  . 2.    $\mathbb{E}|T^{-1/2}y_{0}|^{2+\delta_{u}}<C$  , and    $\mathbb{E}|\Delta y_{i}|^{2+\delta_{u}}<C$   for    $i\in\{-k+2,.\,.\,.\,,0\}$  .  

Figure 2.1 displays a typical sample path for the dynamic Tobit (2.1), under the preceding assumptions.  

  

Figure 2.1.  y  $\begin{array}{r}{y_{t}=\left\lfloor\frac{1}{T^{1/2}}+\left(1-\frac{5}{T}\right)y_{t-1}+u_{t}\right\rfloor_{+}}\end{array}$  ,    $y_{0}=0$  ,    $u_{t}\sim\mathrm{i.i.d}$  .    ${\mathcal{N}}(0,1)$  ,    $T=500$  .  

The main consequences of our assumptions may be summarised as follows.  

$\begin{array}{r}{T^{-1/2}\sum_{t=1}^{\lfloor r T\rfloor}u_{t}\ \xrightarrow{d}\ \sigma W(r)}\end{array}$  (i)  e functi central limit theorem,  A2.1  implies   → ) on  $D[0,1]$   1], where  $W(\cdot)$  · ) is a standard Brownian motion. This convergence alone is suﬃcient to determine the asymptotics of    $T^{-1/2}y_{\lfloor r T\rfloor}$  , and of the OLS estimators, when    $k=1$  (Theorems 3.1 and 3.3 below), but extending these results to    $k\geq2$   necessitates the slightly stronger conditions on    $\{{u}_{t}\}$   provided by  A3 .  

(ii) In the absence of censoring,  would entail that    $y_{t}$   has an autoregressive root within a    ${\cal O}(T^{-1})$   neighbourhood of real unity. Just as in that case, we shall show that in the present setting    $T^{-1/2}y_{\lfloor r T\rfloor}$  converges weakly to a continuous process, albeit one that diﬀers importantly from the diﬀusion process limit familiar from the uncensored case. (iii) We require    $\alpha=O(T^{-1/2})$   in  A2.2 , to ensure that the drift in    $\{y_{t}\}$   is of no larger order than the stochastic trend component. If this assumption were relaxed, so that e.g.    $\alpha$  were now a non-zero constant, the large-sample behaviour of    $\{y_{t}\}$   and the asymptotics of the OLS estimators would be quite diﬀerent from those developed here. A ﬁxed positive    $\alpha$   would generate an increasing linear trend, driving    $y_{t}$   ever further away from origin and making the censoring ultimately irrelevant; whereas a ﬁxed negative    $\alpha$   can lead to    $\{y_{t}\}$   being stationary (see e.g. Bykhovskaya, 2023, Theorem 3). (iv) The speciﬁc para met r is at ions in  A2.2  are chosen merely for convenience: all of our results also hold when    $\alpha_{T}$   and    $\beta_{T}$   more generally satisfy    $T^{1/2}\alpha_{T}\to a$   and    $T(\beta_{T}-1)\rightarrow$   $c$  . For ease of notation, we shall routinely suppress the    $T$   subscripts on    $\alpha_{T}$   and    $\beta_{T}$  throughout the following. (v) Assumptions  A1  and  A3  imply that    $T^{-1/2}y_{i}\stackrel{p}{\rightarrow}b_{0}$   for all    $i\in\{-k+1,.\,.\,.\,,0\}$  .  

2.2. Non-zero lower bound.  Our machinery extends straightforwardly to the case where  $y_{t}$   is censored at some    $\mathbf{L}\neq0$  . Suppose (2.1) is modiﬁed to  

$$
y_{t}=\operatorname*{max}\left\{\mathbf{L},\ \alpha+\beta y_{t-1}+\sum_{i=1}^{k-1}\phi_{i}\Delta y_{t-i}+u_{t}\right\},
$$  

and take    $\mathbf{L}=T^{1/2}{\boldsymbol{\ell}}$  for some    $\ell\in\mathbb R$  , to allow the censoring point to be of the same order of magnitude as    $\{y_{t}\}$  . Deﬁning   $\tilde{y}_{t}:=y_{t}-\mathbf{L}$   −  and subtracting    $\mathbf{L}$   from both sides of (2.3), it may be veriﬁed that  

$$
\tilde{y}_{t}=\left[\tilde{\alpha}+\beta\tilde{y}_{t-1}+\sum_{i=1}^{k-1}\phi_{i}\Delta\tilde{y}_{t-i}+u_{t}\right]_{+}
$$  

where   $\tilde{\alpha}:=\alpha+(\beta-1)\mathbf{L}$   − . Thus,    $\{\tilde{y}_{t}\}$  }  follows a dynamic Tobit with censoring at zero, with drift  

$$
T^{1/2}\tilde{\alpha}=T^{1/2}[\alpha+(\beta-1)T^{1/2}\ell]\rightarrow a+c\ell=:\tilde{a}
$$  

and initialisation  

$$
\tilde{b}_{0}=\operatorname*{lim}_{T\to\infty}T^{-1/2}\tilde{y}_{0}=\operatorname*{lim}_{T\to\infty}T^{-1/2}(y_{0}-\mathbf{L})=b_{0}-\ell.
$$  

All our results hold in the setting of (2.3), with appropriate modiﬁcations. For simplicity, we work with    $\mathbf{L}=0$   throughout the rest of the paper, except where otherwise indicated.  

2.3. Alternative representation.  It will be occasionally useful to rewrite (2.1) in a form that helps to clarify the connections between the dynamic Tobit and the linear autoregressive model. We can do this by deﬁning  

$$
y_{t}^{-}:=\left[\alpha+\beta y_{t-1}+\sum_{i=1}^{k-1}\phi_{i}\Delta y_{t-i}+u_{t}\right]_{-},
$$  

where   $[x]_{-}:=\operatorname*{min}\{x,0\}$  . That is, when    $y_{t}=0$  ,    $y_{t}^{-}$    records the value that    $y_{t}$    would have taken had it not been censored at zero.  

Since   $[x]_{+}=x-[x]_{-}$  , we may then rewrite (2.1) as  

$$
y_{t}=\alpha+\beta y_{t-1}+\sum_{i=1}^{k-1}\phi_{i}\Delta y_{t-i}+u_{t}-y_{t}^{-},
$$  

or equivalently, letting    $L$   denote the lag operator, as  

$$
B(L)y_{t}=\alpha+u_{t}-y_{t}^{-}.
$$  

Thus, if we view    $y_{t}^{-}$    as an additional noise term, (2.6) takes the form of a linear autoregres- sion. The main challenge is that    $y_{t}^{-}$    is itself a complicated non-linear object, whose presence fundamentally alters the dynamics of    $\{y_{t}\}$  , even in the long run.  

2.4. Connections with limited autoregressive processes.  The representation (2.6) al- lows us to draw out the connections between our model and the limited autoregressive pro- cesses developed by Cavaliere (2004, 2005) and Cavaliere and Xu (2014). To put their model – for the special case of a process constrained to lie in   $[0,\infty)$   – in a form comparable to ours, consider a latent process    $\{x_{t}^{*}\}$  } ,  

$$
x_{t}^{*}=\rho_{T}x_{t-1}^{*}+\varepsilon_{t},\quad\rho_{T}=1+c/T,
$$  

where    $\{\varepsilon_{t}\}$   is stationary. Deﬁne an observed process    $\{x_{t}\}$  , whose increments are related to those of    $\{x_{t}^{*}\}$  }  via  

$$
\Delta x_{t}=\Delta x_{t}^{*}+\underline{{\xi}}_{t}
$$  

where    $\underline{{\xi}}_{t}>0$   if and only if    $x_{t-1}+\Delta x_{t}^{*}<0$   0, so as to ensure that    $x_{t}\geq0$   for all    $t$  . In particular, if we set  

$$
\underline{{\xi}}_{t}=-x_{t}^{-}:=-[x_{t-1}+\Delta x_{t}^{*}]_{-}
$$  

then    $\{x_{t}\}$   will be censored at zero. When    $c=0$  , by combining (2.7)–(2.9) we obtain  

$$
x_{t}=x_{t-1}+\varepsilon_{t}-x_{t}^{-}=[x_{t-1}+\varepsilon_{t}]_{+}
$$  

as a valid representation of a limited autoregressive process censored at zero.  

Both (2.6) and (2.10) describe censored processes, but have some subtle, and yet important diﬀerences. Firstly, while    $\{y_{t}\}$   in (2.6) is a Markov process (with state vector   $\left(y_{t},.\cdot.\cdot,y_{t-k+1}\right))$  ,  $\{x_{t}\}$   in (2.10) will be Markov only if    $\{\varepsilon_{t}\}$   is i.i.d. The former is thus more suited to forecasting in the presence of higher-order dynamics. Secondly, at a technical level, the diﬀerences between the models can be seen most clearly by supposing    $\alpha=0$   and    $\beta=1$  , so that    $B(L)=(1\!-\!L)\phi(L)$  in (2.6), where    $\phi(z)$   has all its roots outside the unit circle; and also supposing that    $\varepsilon_{t}~=$   $\phi(L)^{-1}u_{t}$   in (2.7). Then the dynamic Tobit (2.6) can be rewritten as  

$$
y_{t}=y_{t-1}+\varepsilon_{t}-\phi(L)^{-1}y_{t}^{-}.
$$  

Comparing (2.10) and (2.11), we can see that the censoring aﬀects the dynamics of    $\{y_{t}\}$   and

  $\{x_{t}\}$   in diﬀerent ways. Lagged values of    $y_{t}^{-}$    have a direct eﬀect on future    $y_{t}$    (via    $\phi(L)^{-1}y_{t}^{-}=

$   $\textstyle\sum_{i=0}^{\infty}c_{i}y_{t-s}^{-})$  ), whereas lagged    $\textstyle x_{t}^{-}$    have no such eﬀect on    $x_{t}$  . Indeed, the only case in which    $\{y_{t}\}$  − and    $\{x_{t}\}$   will coincide is if    $\phi(L)\,=\,1$   (for a further discussion of which case, see Cavaliere, 2005, Remark 2.3).  

# 3. Asymptotic results  

In this section we derive the weak limits of the standardised process    $T^{-1/2}y_{\lfloor r T\rfloor}$  and the ordinary least squares (OLS) estimators of the parameters of the dynamic Tobit. The latter provides the basis for a unit root test for non-negative time series.  

3.1. Limiting distribution of the regressor process.  Let    $\theta:=(a,b_{0},c)$  , deﬁne the process  

$$
K_{\theta}(r):=b_{0}+a\int_{0}^{r}\mathrm{e}^{-c s}\,\mathrm{d}s+\sigma\int_{0}^{r}e^{-c s}\,\mathrm{d}W(s),
$$  

and denote its ‘regulated’ counterpart by  

$$
J_{\theta}(r):=\mathrm{e}^{c r}\left\{K_{\theta}(r)+\operatorname*{sup}_{r^{\prime}\leq r}[-K_{\theta}(r^{\prime})]_{+}\right\}.
$$  

We ﬁrst provide a result for the case    $k=1$  , under which the model (2.1) reduces to  

$$
y_{t}=[\alpha+\beta y_{t-1}+u_{t}]_{+}.
$$  

Theorem 3.1.  Suppose Assumptions  A1  and  A2  hold with    $k=1$   in  (2.1) . Then on    $D[0,1]$  ,  

$$
T^{-1/2}y_{\lfloor r T\rfloor}\stackrel{d}{\to}J_{\theta}(r).
$$  

The preceding is a new result, which relates to some of the previous literature as follows.  

(i) The supremum in the deﬁnition of    $J_{\theta}(\cdot)$   guarantees non-negativity of the limit- ing process: if    $K_{\theta}(r)$   is negative,   $[-K_{\theta}(r)]_{+}~=~-K_{\theta}(r)~>~0$  , so that    $K_{\theta}(r)\,+$   $\begin{array}{r}{\operatorname*{sup}_{r^{\prime}\leq r}[-K_{\theta}(r^{\prime})]_{+}\;\geq\;0}\end{array}$  . The appearance of the supremum is in line with the solu- tion to the Skorokhod reﬂection problem (Revuz and Yor, 1999, p. 239).  

R  r (ii) Suppose that    $a=b_{0}=0$  . Then   $\begin{array}{r}{\mathrm{e}^{c r}K_{\theta}(r)\,=\,S_{c}(r)\,=\sigma\int_{0}^{r}\mathrm{e}^{c(r-s)}\,\mathrm{d}W(s)}\end{array}$  ), an Ornstein– Uhlenbeck process with autoregressive parameter    $c$   (e.g. Chan and Wei, 1987; Phillips, 1987b), and (3.4) specialises to  

$$
T^{-1/2}y_{\lfloor r T\rfloor}\stackrel{d}{\to}S_{c}(r)+\operatorname*{sup}_{r^{\prime}\leq r}[-\mathrm{e}^{c(r-r^{\prime})}S_{c}(r^{\prime})]_{+}.
$$  

on    $D[0,1]$  . Whereas, if we take    $\varepsilon_{t}\,=\,u_{t}$   in (2.7), the limited autoregressive process (2.7)–(2.9) satisﬁes  

$$
T^{-1/2}x_{\lfloor r T\rfloor}\stackrel{d}{\to}S_{c}(r)+\operatorname*{sup}_{r^{\prime}\leq r}[-S_{c}(r^{\prime})]_{+}
$$  

on    $D[0,1]$  . Comparing the two preceding limits, we observe a subtle but crucial diﬀer- ence, due to the presence of the factor   $\mathrm{e}^{c(r-r^{\prime})}$  .  

(iii) When    $a=b_{0}=c=0$  ,    $J_{\theta}(r)$   coincides with a Brownian motion regulated from below at zero, which has the same distribution as a Brownian motion reﬂected at the origin,  $|W(\cdot)|$  , see e.g. Karatzas and Shreve (2012, p. 97). Another model that generates a process with this asymptotic distribution (upon rescaling by    $T^{-1/2}$  ) is a ﬁrst-order threshold autoregression with ‘unit root’ and ‘stationary’ regimes, as studied by Liu et al.  (2011) and Gao  et al.  (2013). A special case of their model posits  

$$
x_{t}=\beta(x_{t-1})x_{t-1}+u_{t},
$$  

where    $\beta(x)=1$   if    $x\geq0$  , and    $\beta(x)=0$   otherwise. It follows that    $x_{t}=[x_{t-1}]_{+}+u_{t}$  , and so   $[x_{t}]_{+}=[[x_{t-1}]_{+}+u_{t}]_{+}$  , which corresponds to our setting (2.1) with    $\alpha\,=\,0$  ,    $\beta=1$  ,  $k\,=\,1$  , and    $y_{t}\,=\,[x_{t}]_{+}$  . It is thus not surprising that, in this case, our Theorem 3.1 agrees exactly with the corresponding Theorem 3.1 of Liu  et al.  (2011).  

When    $k>1$  , the other roots of the lag polynomial    $B(L)$   aﬀect the behaviour of    $\{y_{t}\}$  , and we need a further condition to ensure that the ﬁrst diﬀerences    $\{\Delta y_{t}\}$   are well behaved. Let  

$$
\begin{array}{r}{F_{\delta}:=\left[\begin{array}{c c c c c c}{\phi_{1}\delta}&{\phi_{2}}&{\cdots}&{\phi_{k-2}}&{\phi_{k-1}}\\ {\delta}&{0}&{\cdots}&{0}&{0}\\ {0}&{1}&&&&&\\ &&{\ddots}&&&&&\\ &&&&{1}&{0}\end{array}\right].}\end{array}
$$  

Under an appropriate condition on the matrices    $\{F_{\delta}\ |\ \delta\,\in\,[0,1]\}$  , we can ensure    $\{\Delta y_{t}\}$   is stochastically bounded. To state that, we need the following (cf. Jungers (2009), Defn. 1.1):  

Deﬁnition.  The  joint spectral radius  (JSR) of a bounded collection  $\mathcal{A}$   of square matrices is  

$$
\lambda_{\mathrm{JSR}}(\mathcal{A}):=\operatorname*{lim}_{n\to\infty}\operatorname*{sup}_{M\in\mathcal{A}^{n}}\lambda(M)^{1/n}
$$  

where    $\lambda(M)$   denotes the spectral radius of    $M$  , and    $\begin{array}{r}{\mathcal{A}^{n}:=\{\prod_{i=1}^{n}A_{i}\mid A_{i}\in\mathcal{A}\}}\end{array}$   |  ∈A} .  

Control over the JSR has been previously used to ensure the stationarity of regime-switching autoregressive models (e.g., Liebscher (2005); Saikkonen (2008)), and we shall utilise it in a similar manner here.  

Assumption  A4 .    $\lambda_{\mathrm{JSR}}(\{F_{0},F_{1}\})<1$  .  

Approximate upper bounds for the JSR can be computed numerically, to an arbitrarily high degree of accuracy, via semideﬁnite programming (Parrilo and Jadbabaie, 2008), making it reasonably straightforward to verify whether this condition is satisﬁed by given parameter values. The following result, which is proved in Appendix C, provides a suﬃcient condition for  A4 , which may be checked even more simply.  

Lemma 3.1.  If  $\begin{array}{r}{\sum_{i=1}^{k-1}|\phi_{i}|<1}\end{array}$  | | , then Assumption  A4  is satisﬁed.  

Remark  3.1 .  Assumption  A4  implies that all the eigenvalues of    $F_{1}$   must be below 1 in modulus, and thus that the all roots of    $\phi(z)$   lie strictly outside the unit circle (see e.g. Hamilton, 1994, Prop. 1.1). (Since    $\phi(0)=1$  , it also follows that    $\phi(1)>0$  .)  

However, as illustrated by Example 1 in Appendix C, merely requiring that    $\phi(z)$   have only stationary roots is not suﬃcient to guarantee the convergence (in distribution) of    $T^{-1/2}y_{\lfloor r T\rfloor}$  . Due to the nonlinearity in the model it may be possible to induce explosive trajectories for both   $\Delta{y}_{t}$   and    $y_{t}$  , via a sucession of periods in which    $y_{t}>0$   alternates with    $y_{t}=0$   (see Figure C.1a). Thus additional conditions, such as  A4 , are needed to exclude such behaviour.  

On the other hand, as illustrated by Example 2 in Appendix C, neither is Assumption  A4 necessary for the convergence of    $T^{-1/2}y_{\lfloor r T\rfloor}$  . Finding a necessary condition thus remains a challenging open question.  

Theorem 3.2.  Suppose Assumptions  A1 – A4  hold. Then  

$$
T^{-1/2}y_{\lfloor r T\rfloor}\stackrel{d}{\to}\phi(1)^{-1}J_{\theta_{\phi}}(r)=:Y_{\theta_{\phi}}(r)
$$  

on    $D[0,1]$  , where    $\theta_{\phi}:=[a,\phi(1)b_{0},\phi(1)^{-1}c]$  .  

The principal diﬀerence between Theorems 3.1 and 3.2 is that when    $k>1$  , the stationary dynamics appear in the limit via the factor    $\phi(1)$  . Notably, the local autoregressive parameter    $c$  is replaced by    $\phi(1)^{-1}c$   – exactly as it would be if    $\{y_{t}\}$   were generated by a linear autoregression with a root local to unity (cf. Hansen, 1999, p. 599). Indeed,    $\phi(1)=1$   when    $k=1$  , so in this case the two results coincide.  

Corollary 3.1.  For the Tobit model  (2.3)  with censoring point  L ,    $T^{-1/2}\tilde{y}_{\lfloor r T\rfloor}\overset{d}{\to}Y_{\tilde{\theta}_{\phi}}(r)$  , where

  $\tilde{\theta}_{\phi}:=[\tilde{a},\phi(1)\tilde{b}_{0},\phi(1)^{-1}c]$  .  

3.2. OLS estimates.  We ﬁrst consider the case where    $k\,=\,1$  , as in the model (3.3), to develop intuition for our results.  

When estimating (3.3) by OLS, we need to decide which deterministic terms should be included in the regression. In the absence of censoring, i.e. if the data generating process were simply a linear autoregression, the inclusion of a constant and a linear trend would render the distribution of the OLS estimator of    $\beta$   free of any nuisance parameters related to the deterministic components.   Unfortunately, the nonlinearity introduced by the censoring entails that    $\alpha$   – or rather, the local parameter    $a$   – will show up in the limiting distribution of  $\hat{\beta}_{T}$  ,  irrespective  of which deterministics are included in the regression. To permit inferences to also be drawn on    $a$  , if required, we consider the OLS regression of    $y_{t}$   on a constant and    $y_{t-1}$  , i.e.  

$$
\left[\!\!\begin{array}{c}{\hat{\alpha}_{T}}\\ {\hat{\beta}_{T}}\end{array}\!\!\right]:=\left(\sum_{t=1}^{T}\left[\!\!\begin{array}{c c}{1}&{y_{t-1}}\\ {y_{t-1}}&{y_{t-1}^{2}}\end{array}\!\!\right]\right)^{-1}\sum_{t=1}^{T}\left[\!\!\begin{array}{c}{1}\\ {y_{t-1}}\end{array}\!\!\right]y_{t}=:\mathcal{M}_{T}^{-1}m_{T}.
$$  

In the stationary dynamic Tobit model, OLS is inconsistent (see e.g., Bykhovskaya, 2023, Supplementary Material, Lemma B.1). However, as the following shows, when    $\beta$   is local to unity, consistency is restored. The reason is that observations in the vicinity of zero accumulate only at rate    $T^{1/2}$  , so that a vanishingly small fraction of the sample is aﬀected by the censoring.  

Theorem 3.3.  Suppose Assumptions  A1  and  A2  hold, with    $k=1$   in  (2.1) . Then  

$$
\begin{array}{r l}&{\left[T^{1/2}(\hat{\alpha}_{T}-\alpha)\right]\xrightarrow{d}\,\left[\begin{array}{c c}{1}&{\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r}\\ {T(\hat{\beta}_{T}-\beta)}\end{array}\right]^{-1}\left[\begin{array}{c c}{J_{\theta}(1)-c\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r-b_{0}-d r}\\ {\sigma\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}W(r)}\end{array}\right]^{-1}}\\ &{\qquad\qquad=:\mathcal{J}_{\theta}^{-1}\mathcal{U}_{\theta}=:\left[\begin{array}{c c}{\mathfrak{a}_{\theta}}\\ {\mathfrak{b}_{\theta}}\end{array}\right].}\end{array}
$$  

2 Strictly speaking, this is true only if the autoregressive model is formulated in ‘unobserved components’ form (see e.g. Andrews and Chen (1994, Section 2.1) as  

$$
y_{t}=\mu+\delta t+y_{t}^{*}\qquad\qquad\qquad\qquad\qquad y_{t}^{*}=\beta y_{t-1}^{*}+u_{t}
$$  

so that the presence (or absence) of a linear drift in    $y_{t}$   is independent of the value of    $\beta$  , and so can always be removed by deterministic detrending. By contrast, if the model is formulated ‘directly’ as  

$$
y_{t}=\alpha+\beta y_{t-1}+u_{t},
$$  

then the linear trend that is present when    $\beta=1$   becomes an exponential trend when    $\beta$   is local to unity. In the present (censored) setting, we may note that (3.3) is  not  equivalent to  

$$
y_{t}=[\mu+\delta t+y_{t}^{*}]_{+}\mathrm{~\\\\\\\\\\\\\\\\\\}y_{t}^{*}=\beta y_{t-1}^{*}+u_{t}.
$$  

(This model is in fact the  latent  dynamic Tobit referred to in Section 1.)  

R  1 Remark  3.2 .  Letting    $\begin{array}{r}{J_{\theta}^{\mu}(r)\,:=\,J_{\theta}(r)\,-\,\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r}\end{array}$  , an alternative expression for the limiting distribution of  $\hat{\beta}_{T}$   is given by  

$$
\mathfrak{b}_{\theta}=\frac{J_{\theta}^{\mu}(1)^{2}-J_{\theta}^{\mu}(0)^{2}-\sigma^{2}}{2\int(J_{\theta}^{\mu}(r))^{2}\,\mathrm{d}r}-c.
$$  

This agrees with the limiting distribution that would be obtained in the linear autoregressive model, except with    $J_{\theta}(\cdot)$   taking the place of the usual Ornstein–Uhlenbeck process. (See Appendix A.2 for details.)  

For the case of general    $k\geq1$  , let    $\phi:=(\phi_{1},.\,.\,.\,,\phi_{k-1})^{\mathsf{T}}$  , and  

$$
({\hat{\alpha}}_{T},{\hat{\beta}}_{T},{\hat{\phi}}_{1,T},\dots,{\hat{\phi}}_{k-1,T}):=\operatorname*{argmin}_{(a,b,f_{1},\dots,f_{k-1})}\sum_{t=1}^{T}\left(y_{t}-a-b y_{t-1}-\sum_{i=1}^{k-1}f_{i}\Delta y_{t-i}\right)^{2}
$$  

denote the OLS estimators of the parameters of (2.1). Since, as the next results shows, the limiting distributions of   $\left({\hat{\alpha}}_{T},{\hat{\beta}}_{T}\right)$  ) depend on    $\phi(1)$  , a consistent estimate of that quantity is needed to compute valid critical values for test statistics based on these estimators. The following also guarantees the consistency of  $\begin{array}{r}{\hat{\phi}(1):=1-\sum_{i=1}^{k-1}\hat{\phi}_{i,T}}\end{array}$   − .  

Theorem 3.4.  Suppose Assumptions  A1 – A4  hold. Then    $\hat{\phi}_{T}\stackrel{p}{\rightarrow}\phi$  → , and  

$$
\begin{array}{r}{\left[\begin{array}{c}{T^{1/2}(\hat{\alpha}_{T}-\alpha)}\\ {T(\hat{\beta}_{T}-\beta)}\end{array}\right]\overset{d}{\to}\left[\begin{array}{c c}{1}&{\int Y_{\theta_{\phi}}(r)\,\mathrm{d}r}\\ {\int Y_{\theta_{\phi}}(r)\,\mathrm{d}r}&{\int Y_{\theta_{\phi}}^{2}(r)\,\mathrm{d}r}\end{array}\right]^{-1}\left[\phi(1)[Y_{\theta_{\phi}}(1)-b_{0}-c_{\phi}\int Y_{\theta_{\phi}}(r)\,\mathrm{d}r\right]^{-1}\,,}\end{array}
$$  

Remark  3.3 .  The parameters of the Tobit model (2.3) with censoring point    $\mathbf{L}$   can be estimated as in (3.10), with   $\tilde{y}_{t}$   in place of    $y_{t}$   and with   $\tilde{\theta}_{\phi}$   replacing    $\theta_{\phi}$   in (3.11).  

3.3. Unit root tests.  The preceding results allow us to conduct asymptotically valid hypo- thesis tests on key parameters of the dynamic Tobit: in particular, to test the hypothesis of a unit root in this setting. This may be of interest for several reasons. For example, whether the variance of the errors made in forecasting    $y_{t}$   remains bounded, or grows without bound at progressively longer forecast horizons, depends crucially on the presence of a unit root. In a setting with multiple series, one or more of which are non-negative, the presence of unit roots may also lead to spurious regressions or, more constructively, allow long-run equilibrium rela- tionships to be identiﬁed from the (nonlinear) cointegrating relationships between the series (see Duﬀy  et al. , 2022).  

In a linear autoregressive model, the presence of a unit root – equivalently, the sum of the autoregressive coeﬃcients being unity (  $\beta=1$  ) – necessarily imparts a stochastic trend to  $\{y_{t}\}$  . However, in the dynamic Tobit the value of the intercept also matters. In particular, a negative intercept (  $\alpha<0$  ) would continually push the process back towards the censoring point, thereby rendering it stationary (for    $k=1$  , see Bykhovskaya, 2023, Theorem 3). Thus to the extent that the purpose of a test for a unit root is to test for the presence of a stochastic trend in    $\{y_{t}\}$  , rather than to detect a unit root per se, it may be considered more appropriate to test the null that    $\alpha=0$   and    $\beta=1$  , as opposed to merely the restriction that    $\beta=1$  , with it being desirable to reject this null in favour of a stationary alternative, when either    $\beta<1

$  (exactly as in a linear model), or when    $\beta=1$   but    $\alpha<0$  .  

To construct our test statistics, we need an estimate of the error variance    $\sigma^{2}$  . We use

  $\begin{array}{r}{\hat{\sigma}_{T}^{2}:=\frac{1}{T}\sum_{t=1}^{T}\hat{u}_{t}^{2}}\end{array}$  , where  

$$
\hat{u}_{t}:=y_{t}-\hat{\alpha}_{T}-\hat{\beta}_{T}y_{t-1}-\sum_{i=1}^{k-1}\hat{\phi}_{i,T}\Delta y_{t-i}.
$$  

That is,    $\left\{\hat{u}_{t}\right\}$  }  are the OLS residuals, computed as if    $y_{t}$   were not subject to censoring. Let  $\begin{array}{r}{\mathcal{M}_{T}:=\sum_{t=1}^{T}\pmb{x}_{t}\pmb{x}_{t}^{\top}}\end{array}$  , where    $\pmb{x}_{t}:=(1,y_{t-1},\Delta y_{t-1},.\,.\,.\,,\Delta y_{t-k+1})^{\mathsf{T}}$  .  

Corollary 3.2.  Suppose Assumptions  and  hold. If either:    $k=1$   in  (2.1) ; or    $k\,>\,1$  ,  A1  A2  $\hat{\sigma}_{T}^{2}\xrightarrow{p}\sigma^{2}$    and  A3  and  A4  hold, then   → and  

$$
t_{\alpha,T}:=\frac{\hat{\alpha}_{T}-\alpha}{\hat{\sigma}\sqrt{\mathcal{M}_{T}^{-1}(1,1)}}\overset{d}{\to}\frac{\mathfrak{a}_{\theta_{\phi}}}{\sigma\sqrt{\mathcal{I}_{\theta_{\phi}}^{-1}(1,1)}}\quad t_{\beta,T}:=\frac{\hat{\beta}_{T}-\beta}{\hat{\sigma}\sqrt{\mathcal{M}_{T}^{-1}(2,2)}}\overset{d}{\to}\frac{\mathfrak{b}_{\theta_{\phi}}}{\sigma\sqrt{\mathcal{I}_{\theta_{\phi}}^{-1}(2,2)}}.
$$  

where    $\mathcal{M}_{T}^{-1}(i,j)$   denotes the    $(i,j)$   element of    $\mathcal{M}_{T}^{-1}$  .  

This result allows us to conduct a one-sided test of a unit root versus a stationary alternative, which rejects when    $t_{\beta,T}\leq c$  , where    $c$   is drawn from an appropriate quantile of the asymptotic distribution of    $t_{\beta}$  . As the simulations in the following section illustrate, such a test indeed has the desirable properties outlined above, in the sense of tending to reject both when either  $\beta<1$  , or when (  $\beta=1,~\alpha<0\}$  ), i.e. it has power to reject the null whenever    $\{y_{t}\}$   is stationary.  

# 4. Simulations  

We now illustrate how the values of the initial condition    $b_{0}$   and the localising parameters  $a$   and    $c$   aﬀect the distribution of    $t_{\beta}$  , and compare the performance of a test based on critical values derived from Corollary 3.2 with one based on the conventional ADF critical values

 (Dickey and Fuller, 1979), when the data is subject to censoring.  

4.1. Eﬀect of    $b_{0}$  .  Figure 4.1 depicts how a change in    $b_{0}$   shifts the density of    $t_{\beta}$  . As    $b_{0}$   moves further above zero, the density shifts progressively to the right, as the probability that any trajectory of    $K_{\theta}$   (initialised at    $b_{0}$  ) will reach zero, and so be subject to censoring, correspond- ingly declines. Indeed, once    $b_{0}$   is suﬃciently large to make this probability negligible, the density becomes indistinguishable from that generated by a linear model (the solid green line  

  
Figure 4.1.  Densities of    $t_{\beta}$   under the Tobit and linear models. Data generating process is    $y_{t}=[y_{t-1}+u_{t}]_{+}$  ,    $y_{0}=b_{0}\sqrt{T}$  √  for Tobit model and    $y_{t}^{\ell}=y_{t-1}^{\ell}{+}u_{t}$  ,   $y_{0}^{\ell}=0$  − for a li el,    $u_{t}\sim$  i.i.d.    ${\mathcal{N}}(0,1)$  . Data is obtained from   $10^{6}$    samples of length  T  = 1000.  

in Figure 4.1), which is invariant to    $b_{0}$  . (Under the parametrisation used in the ﬁgure, this occurs when    $b_{0}=2$  ; in general, this will depend on the magnitude of    $\phi(1)b_{0}/\sigma$  , in accordance with Theorem 3.2.)  

For the remainder of this section, all simulations are conducted with    $y_{0}=b_{0}=0$  .  

4.2. Eﬀects of    $a$   and    $c$  .  Figure 4.2 shows how a change in local intercept    $a$   (left panel) and local slope coeﬃcient    $c$   (right panel) aﬀects the density of    $t_{\beta}$  . The means of these distributions across a range of values for    $a$   and    $c$   are also reported in Table 4.1. We can see that as    $a$   or    $c$   fall further below zero, the distribution of    $t_{\beta}$   (both its mean and its entire probability mass) shifts leftward – with the opposite eﬀect being observed when these parameters are progressively raised above zero.  

4.3. Power.  The preceding illustrates how changes in    $a$   and/or    $c$   may shift the distribution of    $t_{\beta}$   in either direction, and so will aﬀect the ability of the test to reject the null of a unit root (i.e.    $H_{0}:\alpha=0,\beta=1\}$  ). Power envelopes (rejection probabilities for a nominal 5 per cent, one-sided test), are displayed in Figure 4.3. These show that, on the one side, more negative values of    $a$   and/or    $c$   make it easier for the test to reject the null in favour of a stationary alternative. The power eventually reaches 100 per cent, indicating the consistency of the test against ﬁxed alternatives in this region. This tendency to reject the null, as    $a$   falls below zero, is in fact a desirable property of the test in this setting, since having    $\alpha\,<\,0$   in the dynamic Tobit implies (for    $k\,=\,1$  ) that    $\{y_{t}\}$   is stationary, even when    $\beta\,=\,1$   (Bykhovskaya, 2023, Theorem 3).  

  
(a)  Eﬀect of a change in    $a$   when    $c=0$  . (b)  Eﬀect of a change in    when    $a=0$  .  $c$  

<td><table  border="1"><thead><tr><td><b>c</b></td><td rowspan="2"><b>-5</b></td><td rowspan="2"><b>-2</b></td><td rowspan="2"><b>-1</b></td><td rowspan="2"><b>0</b></td><td rowspan="2"><b>1</b></td><td rowspan="2"><b>2</b></td><td rowspan="2"><b>5</b></td></tr><tr><td><b>a</b></td></tr></thead><tbody><tr><td>-5</td><td>-6.09</td><td>-5.70</td><td>-5.56</td><td>-5.42</td><td>-5.26</td><td>-5.09</td><td>-4.37</td></tr><tr><td>-2</td><td>-4.24</td><td>-3.70</td><td>-3.49</td><td>-3.27</td><td>-3.00</td><td>-2.62</td><td>8.93</td></tr><tr><td>-1</td><td>-3.69</td><td>-3.10</td><td>-2.88</td><td>-2.62</td><td>-2.26</td><td>-1.51</td><td>23.05</td></tr><tr><td>0</td><td>-3.20</td><td>-2.60</td><td>-2.37</td><td>-2.06</td><td>-1.46</td><td>0.03</td><td>43.23</td></tr><tr><td>1</td><td>-2.82</td><td>-2.26</td><td>-2.00</td><td>-1.56</td><td>-0.57</td><td>1.85</td><td>68.26</td></tr><tr><td>2</td><td>-2.58</td><td>-2.06</td><td>-1.76</td><td>-1.13</td><td>0.28</td><td>3.68</td><td>96.73</td></tr><tr><td>5</td><td>-2.52</td><td>-2.05</td><td>-1.57</td><td>-0.48</td><td>2.18</td><td>9.00</td><td>193.14</td></tr></tbody></table></td>  

Table 4.1. is  $\begin{array}{r}{y_{t}=\left[\frac{a}{\sqrt{T}}+\left(1+\frac{c}{T}\right)y_{t-1}+u_{t}\right]_{+}}\end{array}$   Mean of t-ratio       $t_{\beta}$   for various values of i ,    $y_{0}=0$  ,    $u_{t}\sim\mathrm{i.i.d}$     $a,c$  .    ${\mathcal{N}}(0,1)$  . Data generating process . Data is obtained from 10   samples of time series of length    $T=1000$  .  

On the other side, positive values of    $c$   move    $\{y_{t}\}$   into the explosive region, and our tendency to not reject in these cases is entirely consistent with the use of a one-sided test, as it is in a linear model (Figure 4.3b). Although we also fail to reject for suﬃciently positive values of  $a$   (Figure 4.3a), in such cases an upward trend in    $\{y_{t}\}$   would become discernable, and would carry the process away from the censoring point. Since    $\{y_{t}\}$   would then make few (if any) visits to the censoring point, if one were interested in testing the null of a unit root against a  trend  stationary alternative, in this case, a conventional ADF test with intercept and trend would be appropriate.  

4.4. Autoregression vs. dynamic Tobit.  Figure 4.4 shows the cumulative distributions

 (CDF) and probability densities (PDF) for    $t_{\beta}$   under dynamic Tobit and linear autoregressive  

  
(a)  Power envelopes with respect to    $a$  .  

  
(b)  Power envelopes with respect to    $c$  .  

$\begin{array}{r}{y_{t}\=\left[\frac{a}{\sqrt{T}}+\left(1+\frac{c}{T}\right)y_{t-1}+u_{t}\right]_{+}}\end{array}$  Figure 4.3.    Power envelopes with respect to  i ,    $y_{0}\,=\,0$  ,    $u_{t}\sim$     $a$  i.i.d.  and    $c$   $\mathcal{N}(0,1)$  . Data generating process . Data is obtained + from 10   samples of time series of length    $T=1000$  .  

  
(a)  Probability density functions.  

  
(b)  Cumulative distribution functions.  

data generating processes, with the distribution for the former lying to the left of that for the latter. Thus when data is generated by a dynamic Tobit with a unit root, the conventional ADF test (i.e. that which compares    $t_{\beta}$   to critical values derived from the linear model) will tend to over-reject: we ﬁnd that a nominal 5 per cent test will in fact reject 18 per cent of the time. The intuition for this is that the censoring causes the trajectories of    $\{y_{t}\}$   to appear stationary, masking the presence of a unit root.  

<td><table  border="1"><thead><tr><td><b>Size</b></td><td><b>1%</b></td><td><b>5%</b></td><td><b>10%</b></td></tr></thead><tbody><tr><td>ADF</td><td>-3.44</td><td>-2.87</td><td>-2.57</td></tr><tr><td>Tobit ADF (bo = 0)</td><td>-4.53</td><td>-3.67</td><td>-3.25</td></tr></tbody></table></td>  

  
Figure 5.1.  CHF/EUR exchange rate (Source: ECB).  

Table 4.2 summarises the preceding observations by reporting critical values from the con- ventional ADF distribution, and from those based on the dynamic Tobit model, as per Corol- lary 3.2 (with    $b_{0}=0$  ). The former critical values are uniformly larger than the latter, which again indicates that the conventional ADF test is more likely to reject the null of a unit root.  

# 5. Empirical application  

In this section we illustrate the use of our methods through an application to testing for unit roots in nominal exchange rates, when these are subject to a one-sided bound. Unit roots are routinely detected in these series by conventional tests in empirical work (see e.g. Baillie and Bollerslev, 1989; Sarno and Valente, 2006, p. 3156; Hong and Phillips, 2010, p. 107). Their presence is also manifested in the robust performance of exchange rate forecasts based on random walks, which more elaborate models have struggled to beat consistently (Rossi, 2013). Here we examine how censoring, as introduced by the deliberate action of a central bank to keep exchange rates above (or below) a nominated threshold, may alter our assessment of the evidence for or against a unit root, depending on whether that censoring is accounted for (cf. Cavaliere, 2005, Sec. 6.1).  

In September 2011, in response to the ongoing appreciation of the Swiss franc, and with the policy rate eﬀectively at the zero lower bound, the Swiss National Bank (SNB) instituted a ﬂoor on the euro–Swiss franc exchange rate of 1.20 francs per euro (Jordan, 2016; Hertrich, 2022). With the exchange rate well below the ﬂoor on the previous day, the immediate intervention of the SNB was required to make the ﬂoor eﬀective upon its introduction on 6 September. The ﬂoor remained in eﬀect until the end of 15 January 2015. As can be seen from Figure 5.1, during that period, the exchange rate spent most of its time well above the the ﬂoor (reaching a peak of 1.26 in May 2013), with two notable exceptions: the periods of April to August 2012, and from November 2014 until the end of the policy, both of which triggered action by the SNB to prevent the ﬂoor from being violated (see Figure 9 in Hertrich, 2022). (For a further discussion of the ﬂoor and its aftermath, see also von Schweinitz  et al. , 2021.) The observed trajectory of the exchange rate, during these episodes, is thus more plausibly consistent with a dynamic Tobit than it is with a linear autoregression.  

Our data is drawn from the European Central Bank’s (ECB) daily reference exchange rate series (code: EXR.D.CHF.EUR.SP00.A) from the period during which the ﬂoor was operational (6 Sep 2011 to 15 Jan 2015), transformed by taking logarithms. To select the lag order    $k$   used to compute    $t_{\beta}$  , we evaluated autoregressive models with    $k\,\in\,\{1,.\,.\,.\,,15\}$   using the Akaike and Bayesian information criteria; both selected a model with only one lag. For this model, we obtained an ADF statistic slightly above    $-2.87$  : so that if the censoring were ignored, and this statistic referred to the conventional ADF critical values (Table 4.2), there would be just suﬃcient evidence to reject the null of a unit root at the ﬁve per cent level. On the other hand, the unit root is not rejected at conventional signiﬁcance levels under the dynamic Tobit. By simulating the asymptotic distribution of    $t_{\beta}$  , given in Corollary 3.2, we compute the    $p$  -value appropriate to the dynamic Tobit as either 0 . 18 (with    $b_{0}=0$   imposed) or 0 . 16 (using   $\hat{b}_{0}\;=\;T^{-1/2}(y_{0}\,-\,\mathbf{L})$   − ) with    $\textbf{L}={\log(1.20)})$  ; similar results also obtain when  $k\,=\,2,3$  . This places    $t_{\beta,T}$   much further from the critical region, thereby lending support to the hypothesis that the data is consistent with a dynamic Tobit model with a unit root.  

# 6. Conclusion  

This paper extends local to unity asymptotics to the setting of a dynamic Tobit model. Censoring fundamentally changes the analysis and requires new tools to derive the asymptotics. We obtain novel limit theorems for convergence to regulated processes, that is, to processes constrained to lie above a threshold. The eﬀect of that censoring on the limiting distribution of our test statistics varies according to the proximity of the initialisation to the censoring point, with the distributions associated with the linear model re-emerging as that initialisation moves suﬃciently far from the censoring point.  

Our results underpin the development of a unit root test appropriate to censored data generated by a dynamic Tobit model. In contrast to the setting of a linear model, here the presence of a stochastic trend entails restrictions on both    $\alpha$   and    $\beta$  , since    $\alpha<0$   (with    $\beta=1$  ) can be consistent with stationarity (and is consistent with stationarity for    $k=1$  ). Nonetheless, a test of this null can still be eﬀected by the usual    $t_{\beta}$   statistic, using adjusted critical values. We provide an empirical illustration of our methods to testing for a unit root in nominal exchange rates, when these are subject to a one-sided bound.  

The results of this paper could be developed further in a number of directions. One possib- ility would be to extend our results beyond the local to unity setting, by allowing for moderate deviations from a unit root (Giraitis and Phillips, 2006), with the aim of establishing (uni- formly) valid conﬁdence intervals for    $\beta$  , as per Mikusheva (2007, 2012) in the linear model. As we depart from the linear model, new types of asymptotics emerge, which may involve    $c$   in diﬀerent ways (cf. Bykhovskaya and Phillips (2018) where    $c$   is no longer a constant but varies with time).  

The analysis of    $c\rightarrow\pm\infty$  for the censored model may be undertaken in conjunction with the derivation of the asymptotics of least absolute deviation (LAD) regression or maximum likelihood estimators of the model, which would enjoy consistency across a wider domain than does OLS. For such extensions, the results of Section 3.1, regarding the asymptotics of    $\{y_{t}\}$  , are likely to be of fundamental importance.  

For another direction in which our analysis could be extended, recall from the introduction that the dynamic Tobit provides the kernel of more elaborate, multivariate models that allow for the possibility of censoring and/or some other threshold-related nonlinearity. The analysis of (exact) unit roots and cointegration, in the setting of such a model, is developed by Duﬀy et al.  (2022), with the aid of our results.  

# Appendix A. Proofs of results for    $k=1$  .  

# A.1. Limiting distribution of    $T^{-1/2}y_{\lfloor n r\rfloor}$  .  

ma Suppose th  $x_{t}=[x_{t-1}+v_{t}]_{+}$  , for    $t=1,\dots,T$  , and    $\begin{array}{r}{T^{-1/2}(x_{0}+\sum_{s=1}^{\lfloor r T\rfloor}v_{s})\xrightarrow{d}}\end{array}$  →  $V(r)$   on  $D[0,1]$  . Then on  $D[0,1]$  ,  

$$
T^{-1/2}x_{\lfloor r T\rfloor}\stackrel{d}{\to}V(r)+\operatorname*{sup}_{r^{\prime}\leq r}[-V(r^{\prime})]_{+}.
$$  

Proof.  By Bykhovskaya (2023, Supplementary Material, Lemma D.8) and Cavaliere (2004, Lemma 1),  

$$
x_{t}=[x_{t-1}+v_{t}]_{+}=x_{0}+\sum_{s=1}^{t}v_{s}+\operatorname*{sup}_{t^{\prime}\in\{0,\ldots,t\}}\left[-x_{0}-\sum_{s=1}^{t^{\prime}}v_{s}\right]_{+}.
$$  

Deﬁning    $\begin{array}{r}{V_{T}(r):=T^{-1/2}(x_{0}+\sum_{s=1}^{\lfloor r T\rfloor}v_{s})}\end{array}$  ), we have that    $V_{T}(r)\ {\overset{d}{\to}}\ V(r)$  → ) on    $D[0,1]$   by the hypo- theses of the lemma. Since  

$$
T^{-1/2}x_{\lfloor r T\rfloor}=V_{T}(r)+\operatorname*{sup}_{r^{\prime}\in[0,r]}[-V_{T}(r^{\prime})]_{+}
$$  

and the supremum on the r.h.s. is a continuous functional of    $V_{T}(\cdot)$  , the result follows by the continuous mapping theorem (CMT). □ Proof of Theorem 3.1.  Multiplying (3.3) by    $\beta^{-t}$  , and deﬁning    $x_{t}:=\beta^{-t}y_{t}$  , we have  

$$
x_{t}=\beta^{-t}y_{t}=\beta^{-t}[\beta y_{t-1}+\alpha+u_{t}]_{+}=[\beta^{-(t-1)}y_{t-1}+\beta^{-t}(\alpha+u_{t})]_{+}=[x_{t-1}+v_{t}]_{+}=[x_{t}+v_{t}]_{-}
$$  

where    $v_{t}:=\beta^{-t}\big(\alpha+u_{t}\big)$  . Under  A1 ,    $T^{-1/2}x_{0}=T^{-1/2}y_{0}\to b_{0}$  , and so  

$$
\begin{array}{c}{\displaystyle\frac{1}{T^{1/2}}\left(x_{0}+\sum_{s=1}^{\lfloor r T\rfloor}v_{s}\right)=\displaystyle\frac{x_{0}}{T^{1/2}}+\displaystyle\frac{a}{T}\sum_{s=1}^{\lfloor r T\rfloor}e^{-c s/T}+\displaystyle\frac{1}{T^{1/2}}\sum_{s=1}^{\lfloor r T\rfloor}e^{-c s/T}u_{s}}\\ {\displaystyle\stackrel{d}{\to}b_{0}+a\int_{0}^{r}e^{-c s}\,\mathrm{d}s+\sigma\int_{0}^{r}e^{-c s}\,\mathrm{d}W(s)=K_{\theta}(r)}\end{array}
$$  

on    $D[0,1]$  , where    $K_{\theta}$   is as deﬁned in (3.1),    $\theta=(a,b_{0},c)$  , and the weak convergence follows by the martingale central limit theorem. It follows by Lemma A.1 that on    $D[0,1]$  ,  

$$
\begin{array}{r}{T^{-1/2}y_{\lfloor r T\rfloor}=\beta^{\lfloor r T\rfloor}T^{-1/2}x_{\lfloor r T\rfloor}=e^{c\lfloor r T\rfloor/T}T^{-1/2}x_{\lfloor r T\rfloor}\stackrel{d}{\to}e^{c r}\left[K_{\theta}(r)+\operatorname*{sup}_{r^{\prime}\leq r}[-K_{\theta}(r^{\prime})]\right]}\end{array}
$$  

A.2. OLS asymptotics.  Recall from (2.4) that, in the AR(1) model,    $y_{t}^{-}=[\alpha+\beta y_{t-1}\!+\!u_{t}]_{-}$  , − − and that in this case (2.5) specialises to  

$$
y_{t}=[\alpha+\beta y_{t-1}+u_{t}]_{+}=\alpha+\beta y_{t-1}+u_{t}-y_{t}^{-}.
$$  

Lemma A.2.  Suppose Assumptions  A1  and  A2  hold with    $k=1$  . Then  

$$
\begin{array}{r l}&{T^{-1/2}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})\xrightarrow{d}J_{\theta}(1)-b_{0}-c\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r-a;}\\ &{\sum_{t=1}^{T}(y_{t}^{-})^{2}=o_{p}(T);\;a n d}\\ &{T^{-1}\sum_{t=1}^{T}(\Delta y_{t})^{2}\xrightarrow{p}\sigma^{2}.}\end{array}
$$  

Proof.  (i).  We ﬁrst note from (A.2) that  

$$
\begin{array}{l l l l}{\displaystyle\sum_{t=1}^{T}(u_{t}-y_{t}^{-})=\displaystyle\sum_{t=1}^{T}(y_{t}-\alpha-\beta y_{t-1})=\displaystyle\sum_{t=1}^{T}(y_{t}-y_{t-1})-(\beta-1)\sum_{t=1}^{T}y_{t-1}-T\alpha}\\ {\displaystyle\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad}\\ {\displaystyle=y_{T}-y_{0}-(\beta-1)\sum_{t=1}^{T}y_{t-1}-T^{1/2}a.}\end{array}
$$  

Since    $T(\beta-1)=c+o(1)$  , it follows from Theorem 3.1 and the CMT that, under  A1 ,  

$$
\begin{array}{c}{\displaystyle\frac{1}{T^{1/2}}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})=\displaystyle\frac{1}{T^{1/2}}(y_{T}-y_{0})-\displaystyle\frac{c+o(1)}{T^{3/2}}\sum_{t=1}^{T}y_{t-1}-a}\\ {\stackrel{d}{\to}J_{\theta}(1)-b_{0}-c\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r-a.}\end{array}
$$  

(ii).  Since    $\beta\geq0$   and    $y_{t-1}\geq0$  ,  

$$
0\geq y_{t}^{-}=(\alpha+\beta y_{t-1}+u_{t})\mathbf{1}\{\alpha+\beta y_{t-1}+u_{t}\leq0\}\geq v_{t}\mathbf{1}\{v_{t}\leq-\beta y_{t-1}\},
$$  

where    $v_{t}:=\alpha+u_{t}$  . Hence  

$$
\operatorname*{max}_{1\leq t\leq T}|y_{t}^{-}|\leq\operatorname*{max}_{1\leq t\leq T}|v_{t}|\leq\frac{|a|}{T^{1/2}}+\operatorname*{max}_{1\leq t\leq T}|u_{t}|=o_{p}(T^{1/2})
$$  

where the ﬁnal equality holds since    $\{{u}_{t}\}$   is i.i.d. with ﬁnite variance, under Assumption  A2.1 . Further, by the result of part (i),  

$$
\sum_{t=1}^{T}y_{t}^{-}=\sum_{t=1}^{T}u_{t}+O_{p}(T^{1/2})=O_{p}(T^{1/2}).
$$  

Hence  

$$
\sum_{t=1}^{T}(y_{t}^{-})^{2}\leq\operatorname*{max}_{1\leq t\leq T}\lvert y_{t}^{-}\rvert\sum_{t=1}^{T}\lvert y_{t}^{-}\rvert=-\operatorname*{max}_{1\leq t\leq T}\lvert y_{t}^{-}\rvert\sum_{t=1}^{T}y_{t}^{-}=o_{p}(T^{1/2})O_{p}(T^{1/2})=o_{p}(T^{1/2}).
$$  

(iii).  Since  

$$
\sum_{t=1}^{T}\alpha^{2}=a^{2}=O(1),\qquad\sum_{t=1}^{T}\alpha(\beta-1)y_{t-1}=O_{p}(1),\qquad\sum_{t=1}^{T}[(\beta-1)y_{t-1}]^{2}=O_{p}
$$  

by Theorem 3.1 and the CMT;  

$$
\sum_{t=1}^{T}\alpha\big(u_{t}-y_{t}^{-}\big)=O_{p}(1),
$$  

by Lemma A.2(i); and  

$$
\frac{1}{T}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})^{2}=\frac{1}{T}\sum_{t=1}^{T}u_{t}^{2}-\frac{2}{T}\sum_{t=1}^{T}y_{t}^{-}u_{t}+\frac{1}{T}\sum_{t=1}^{T}(y_{t}^{-})^{2}\stackrel{p}{\rightarrow}\sigma^{2},
$$  

by the law of large numbers, the Cauchy–Schwarz (CS) inequality, and the result of part (ii); and  

$$
\left|\sum_{t=1}^{T}(\beta-1)y_{t-1}(u_{t}-y_{t}^{-})\right|\leq\sqrt{\sum_{t=1}^{T}[(\beta-1)y_{t-1}]^{2}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})^{2}}=O_{p}(\sqrt{T}),
$$  

by the preceding; it follows that  

$$
\frac{1}{T}\sum_{t=1}^{T}(\Delta y_{t})^{2}=\frac{1}{T}\sum_{t=1}^{T}(\alpha+(\beta-1)y_{t-1}+u_{t}-y_{t}^{-})^{2}=\frac{1}{T}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})^{2}+o_{p}(1)\xrightarrow{p}
$$  

Proof of Theorem 3.3.  We have from (A.2) that  

$$
\left[\!\!{\hat{\alpha}}_{T}-\alpha\!\!\right]=\left(\sum_{t=1}^{T}\left[{1\atop y_{t-1}}\!\!\right]\right)^{-1}\sum_{t=1}^{T}\left[{1\atop y_{t-1}}\right]\left(u_{t}-y_{t}^{-}\right)
$$  

where  

$$
\frac{1}{T^{1/2}}\sum_{t=1}^{T}\bigl(u_{t}-y_{t}^{-}\bigr)\stackrel{d}{\to}J_{\theta}(1)-b_{0}-c\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}r-a
$$  

by Lem a A. ). To obtain the  it of    ${\textstyle\sum_{t=1}^{T}y_{t-1}(u_{t}-y_{t}^{-})}$   − ), we note that since only − one of  y  and  y  $y_{t}^{-}$    can be nonzero,  y  $y_{t}y_{t}^{-}\,=\,0$  = 0, and hence    $y_{t}^{-}y_{t-1}\,=\,-y_{t}^{-}\Delta y_{t}$   − . Thus by the CS − inequality and Lemma A.2(ii)–(iii),  

$$
\left|\sum_{t=1}^{T}y_{t}^{-}y_{t-1}\right|=\left|\sum_{t=1}^{T}y_{t}^{-}\Delta y_{t}\right|\leq\left[\sum_{t=1}^{T}(y_{t}^{-})^{2}\sum_{t=1}^{T}(\Delta y_{t})^{2}\right]^{1/2}=o_{p}(T).
$$  

It follows by the preceding and Liang  et al.  (2016, Theorem 2.1) that  

$$
\frac{1}{T}\sum_{t=1}^{T}y_{t-1}\bigl(u_{t}-y_{t}^{-}\bigr)=\frac{1}{T}\sum_{t=1}^{T}y_{t-1}u_{t}+o_{p}(1)\xrightarrow{d}\sigma\int_{0}^{1}J_{\theta}(r)\,\mathrm{d}W(r).
$$  

In view of (A.4)–(A.6), a ﬁnal appeal to Theorem 3.1 and the CMT yields  

$$
\begin{array}{c}{\dot{T}^{1/2}(\hat{\alpha}_{T}-\alpha)\Bigg]=\left(\displaystyle\sum_{t=1}^{T}\left[\!\!\begin{array}{c c}{T^{-1}}&{T^{-3/2}y_{t-1}}\\ {T^{-3/2}y_{t-1}}&{T^{-2}y_{t-1}^{2}}\end{array}\!\!\right]\right)^{-1}\displaystyle\sum_{t=1}^{T}\left[\!\!\begin{array}{c c}{T^{-1/2}}\\ {T^{-1}y_{t-1}}\end{array}\!\!\right]\left(u_{t}-y_{t}^{-}\right)}\\ {\overset{d}{\to}\left[\!\!\begin{array}{c c}{1}&{\int J_{\theta}(r)\,\mathrm{d}r}\\ {\int J_{\theta}(r)\,\mathrm{d}r}&{\int J_{\theta}^{2}(r)\,\mathrm{d}r}\end{array}\!\!\right]^{-1}\left[\!\!\begin{array}{c c}{J_{\theta}(1)-b_{0}-c\int J_{\theta}(r)\,\mathrm{d}r-a}\\ {\sigma\int J_{\theta}(r)\,\mathrm{d}W(r)}\end{array}\!\!\right].}\end{array}
$$  

Veriﬁcation of  (3.9) .  By the Frisch-Waugh-Lovell theorem, and using partial summation (as in the proof of Theorem 3.1 in Phillips (1987a)) we have  

$$
\begin{array}{r l}&{\hat{\boldsymbol{\jmath}}_{T}-1=\frac{\sum_{t=1}^{T}y_{t-1}^{\mu}y_{t}^{\mu}}{\sum_{t=1}^{T}(y_{t-1}^{\mu})^{2}}-1=\frac{\sum_{t=1}^{T}y_{t-1}^{\mu}\Delta y_{t}^{\mu}}{\sum_{t=1}^{T}(y_{t-1}^{\mu})^{2}}}\\ &{\qquad\qquad=\frac{\sum_{t=1}^{T}\big((y_{t-1}^{\mu}+\Delta y_{t}^{\mu})^{2}-(y_{t-1}^{\mu})^{2}-(\Delta y_{t}^{\mu})^{2}\big)}{2\sum_{t=1}^{T}(y_{t-1}^{\mu})^{2}}=\frac{(y_{T}^{\mu})^{2}-(y_{0}^{\mu})^{2}-\sum_{t=1}^{T}(\Delta y_{t}^{\mu})^{2}}{2\sum_{t=1}^{T}(y_{t-1}^{\mu})^{2}}.}\end{array}
$$  

where  $\begin{array}{r}{y_{t}^{\mu}:=y_{t}-\frac{1}{T}\sum_{t=1}^{T}y_{t-1}}\end{array}$    P . (3.9) then follows (noting the centring here is around   $1$  , rather than    $\beta$  ) by Theorem 3.1, Lemma A.2(iii), and the CMT. □  

Proof of Corollary 3.2 (  $k=1$  ).  Once we have shown that   $\hat{\sigma}_{T}^{2}\xrightarrow{p}\sigma^{2}$  → , the limiting distributions of the    $t$   statistics will follow from Theorem 3.1 and the CMT. Noting from (A.2) that  

$$
\hat{u}_{t}=y_{t}-\hat{\alpha}_{T}-\hat{\beta}_{T}y_{t-1}=(\alpha-\hat{\alpha}_{T})+(\beta-\hat{\beta}_{T})y_{t-1}+(u_{t}-y_{t}^{-}),
$$  

and that  $\begin{array}{r}{\sum_{t=1}^{T}\hat{u}_{t}=0}\end{array}$   = 0 and  $\begin{array}{r}{\sum_{t=1}^{T}y_{t-1}\hat{u}_{t}=0}\end{array}$   = 0, we have −  

$$
\sum_{t=1}^{T}[\hat{u}_{t}^{2}-(u_{t}-y_{t}^{-})^{2}]=\sum_{t=1}^{T}[\hat{u}_{t}-(u_{t}-y_{t}^{-})][\hat{u}_{t}+(u_{t}-y_{t}^{-})]
$$  

$$
\begin{array}{r l}{\lefteqn{=\sum_{t=1}^{T}[(\alpha-\hat{\alpha}_{T})+(\beta-\hat{\beta}_{T})y_{t-1}][\hat{u}_{t}+\big(u_{t}-y_{t}^{-}\big)]}}\\ &{=(\alpha-\hat{\alpha}_{T})\sum_{t=1}^{T}(u_{t}-y_{t}^{-})+(\beta-\hat{\beta}_{T})\sum_{t=1}^{T}y_{t-1}\big(u_{t}-y_{t}^{-}\big)}\\ &{=O_{p}(T^{-1/2})O_{p}(T^{1/2})+O_{P}(T^{-1})O_{p}(T)=O_{p}(1)}\end{array}
$$  

where the orders of    $\textstyle\sum_{t=1}^{T}(u_{t}-y_{t}^{-})$   − and    ${\textstyle\sum_{t=1}^{T}y_{t-1}\big(u_{t}-y_{t}^{-}\big)}$   − ) follow from (A.5) and (A.6) above, − and the rates of convergence of ˆ  $\hat{\alpha}_{T}$   and   $\hat{\beta}_{T}$   from Theorem 3.3. Hence, by (A.3),  

$$
\widehat{\sigma}_{T}^{2}=\frac{1}{T}\sum_{t=1}^{T}\widehat{u}_{t}^{2}=\frac{1}{T}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})^{2}+O_{p}(T^{-1})\stackrel{p}{\rightarrow}\sigma^{2}.
$$  

# Appendix B. Proofs of results for general    $k$  

B.1. Limiting distribution of    $T^{-1/2}y_{\lfloor n r\rfloor}$  :   $\mathbf{AR}(k)$   case.  Let    $\rho$   denote the  inverse  of the root of    $B(z)$   closest to real unity, which for    $\mathit{(I)}$   suﬃciently large must be real because  A2  permits  $B(z)$   to have only one root local to unity. Thus    $B(z)$   factorises as  

$$
B(z)=(1-\beta)z+\phi(z)(1-z)=\psi(z)(1-\rho z)
$$  

for    $z\in\mathbb{C}$   where    $\begin{array}{r}{\psi(z)=1-\sum_{i=1}^{k-1}\psi_{i}z^{i}}\end{array}$  . Under  A2.2 ,    $\beta=\beta_{T}\rightarrow1$   and, thus,    $\rho=\rho_{T}\rightarrow1$  , from which it follows that  $\psi_{i}\rightarrow\phi_{i}$   →  for  $i\in\{1,.\,.\,.\,,k-1\}$   ∈{  − } , as    $T\to\infty$  .   Thus for    $T$   suﬃciently large,  $\rho$   is real and positive (as we shall maintain throughout the following), and such a condition as  A4  also holds when each    $\phi_{i}$   in (3.5) is replaced by    $\psi_{i}$  . Moreover, taking    $z\,=\,\rho_{T}^{-1}$  in the preceding, it follows that  

$$
\begin{array}{r l}&{0=B(\rho_{T}^{-1})=(1-\beta_{T})\rho_{T}^{-1}+\phi(\rho_{T}^{-1})(1-\rho_{T}^{-1})}\\ &{\quad\Leftrightarrow T(\rho_{T}-1)=\phi(\rho_{T}^{-1})^{-1}T(\beta_{T}-1)\to\phi(1)^{-1}c=:c_{\phi}.}\end{array}
$$  

The factorisation (B.1) also permits us to rewrite the model (2.6) for    $\{y_{t}\}$   in terms of the quasi-diﬀerences   $\Delta_{\rho}y_{t}$  ,  

$$
\psi(L)\Delta_{\rho}y_{t}=\alpha+u_{t}-y_{t}^{-},
$$  

where   $\Delta_{\rho}:=1-\rho L$  . With the aid of this representation we establish the following preliminary lemmas.  

Lemma B.1.  Suppose Assumption  A2  holds, and deﬁne  

$$
x_{t}:=\psi(\rho^{-1})\rho^{-t}y_{t}\quad\quad\quad\xi_{t}:=\sum_{s=1}^{t}\rho^{-s}(\alpha+u_{s})-\gamma_{\rho}(L)[\rho^{-t}\Delta_{\rho}y_{t}-\Delta_{\rho}y_{0}]
$$  

for    $t\ \ \in\ \ \{1,.\ .\ .\ T\}$  ∈ { } , where    $\gamma_{\rho}(L)$   is the    $k~-~2$   order polynomial such that    $\begin{array}{r l}{\psi(L)}&{{}=}\end{array}$   $\psi(\rho^{-1})+\gamma_{\rho}(L)\Delta_{\rho}$   (with    $\psi(L)=1$   and    $\gamma_{\rho}(L)=0$   when    $k=1$  ). Then for    $t\in\{1,.\,.\,.\,,T\}$  ,  

$$
x_{t}=[x_{t-1}+\Delta\xi_{t}]_{+}.
$$  

Proof.  Observe that for any series    $\{\eta_{s}\}$  ,  

$$
\sum_{s=1}^{t}\rho^{t-s}\Delta_{\rho}\eta_{s}=\sum_{s=1}^{t}\rho^{t-s}(\eta_{s}-\rho\eta_{s-1})=\sum_{s=1}^{t}\rho^{t-s}\eta_{s}-\sum_{s=1}^{t}\rho^{t-(s-1)}\eta_{s-1}=\eta_{t}-\rho^{t}\eta_{s-1}\quad\mathrm{~(~s~o~n~d~)~}
$$  

Applying this to    $\psi(L)\Delta_{\rho}y_{s}=\alpha+u_{s}-y_{s}^{-}$    (from (B.3) above), we obtain  

$$
\psi(L)y_{t}-\rho^{t}\psi(L)y_{0}=\sum_{s=1}^{t}\rho^{t-s}(\alpha+u_{s})-\sum_{s=1}^{t}\rho^{t-s}y_{s}^{-}.
$$  

Using    $\psi(L)=\psi(\rho^{-1})+\gamma_{\rho}(L)\Delta_{\rho}$  , and rearranging yields  

$$
(\rho^{-1})y_{t}+\sum_{s=1}^{t}\rho^{t-s}y_{s}^{-}=\sum_{s=1}^{t}\rho^{t-s}(\alpha+u_{s})-\gamma_{\rho}(L)(\Delta_{\rho}y_{t}-\rho^{t}\Delta_{\rho}y_{0})+\rho^{t}\psi(\rho^{-1})y_{0}.
$$  

Finally, multiplying by    $\rho^{-t}$    and recalling the deﬁnitions of   $(x_{t},\xi_{t})$   from (B.4), we have  

$$
x_{t}+\sum_{s=1}^{t}\rho^{-s}y_{s}^{-}=x_{0}+\xi_{t}.
$$  

To proceed from (B.7) to show that   $\left(x_{t},\xi_{t}\right)$   satisfy (B.5), we note that for    $t\geq1$  ,  

$$
\begin{array}{c}{{\displaystyle\xi_{t+1}=x_{t+1}-x_{0}+\displaystyle\sum_{s=1}^{t+1}\rho^{-s}y_{s}^{-}=x_{t+1}-x_{0}+\rho^{-(t+1)}y_{t+1}^{-}+\displaystyle\sum_{s=1}^{t}\rho^{-s}y_{s}^{-}}}\\ {{=x_{t+1}+\rho^{-(t+1)}y_{t+1}^{-}+\xi_{t}-x_{t}}}\end{array}
$$  

where the ﬁrst and last equalities follow from (B.7). Hence  

$$
x_{t+1}+\rho^{-(t+1)}y_{t+1}^{-}=x_{t}+\Delta\xi_{t+1}.
$$  

From (2.1) and (2.4), at most one of    $y_{t+1}$   and    $y_{t+1}^{-}$    can be nonzero, and must have opposite signs. Since    $\psi(\rho^{-1})\to\phi(1)>0$   (due to stationarity), we must have    $\psi(\rho^{-1})\rho^{-t}>0$   for all    $T$  suﬃciently large. The same must also be true for    $x_{t+1}=\psi(\rho^{-1})\rho^{-(t+1)}y_{t+1}$   and    $\rho^{-(t+1)}y_{t+1}^{-}$  . Hence,  

$$
x_{t+1}=[x_{t}+\Delta\xi_{t+1}]_{+}
$$  

for    $t\geq1$  . Plugging    $\xi_{0}=0$   into (B.7) when    $t=1$  , we have  

$$
x_{1}+\rho^{-1}y_{1}^{-}=x_{0}+\xi_{1}=x_{0}+\Delta\xi_{1}
$$  

and thus    $x_{1}=[x_{0}+\Delta\xi_{1}]_{+}$  , by the same argument.  

Lemma B.2.  Suppose Assumptions  A1 – A4  hold. Then there exists a    $C<\infty$  such that  

$$
\operatorname*{max}_{-k+2\leq t\leq T}(\|\Delta_{\rho}y_{t}\|_{2+\delta_{u}}+\|\Delta y_{t}\|_{2+\delta_{u}})<C.
$$  

Proof.  We have from (B.3) that  

$$
\Delta_{\rho}y_{t}+y_{t}^{-}=\sum_{i=1}^{k-1}\psi_{i}\Delta_{\rho}y_{t-i}+\alpha+u_{t}=:w_{t},
$$  

for    $t\in\{1,.\,.\,.\,,T\}$  . Since, as noted in the proof of Lemma B.1, only one of    $y_{t}$   and    $y_{t}^{-}$    can be nonzero, and have opposite signs,  

$$
\Delta_{\rho}y_{t}>0\implies y_{t}>\rho y_{t-1}\geq0\implies y_{t}^{-}=0.
$$  

It follows that either    $w_{t}>0$  , in which case   $\Delta_{\rho}y_{t}=w_{t}$  ; or    $w_{t}\leq0$  , in which case   $\Delta_{\rho}y_{t}\in[w_{t},0]$  . Hence there exists a    $\delta_{t}\in[0,1]$   such that   $\Delta_{\rho}y_{t}=\delta_{t}w_{t}$   for    $t\in\{1,.\,.\,.\,,T\}$  . Taking    $w_{0}=\Delta_{\rho}y_{0}$  and    $\delta_{0}=1$  , (B.8) is equivalent to a dynamical system deﬁned by  

$$
\begin{array}{c}{{w_{t}=\displaystyle\psi_{1}\delta_{t-1}w_{t-1}+\sum_{i=2}^{k-1}\psi_{i}\Delta_{\rho}y_{t-i}+\alpha+u_{t},}}\\ {{\Delta_{\rho}y_{t-1}=\delta_{t-1}w_{t-1}}}\end{array}
$$  

for    $t\in\{1,.\,.\,.\,,T\}$  , for an appropriate sequence    $\{\delta_{t}\}\subset[0,1]$  . Deﬁning  

$$
\mathbf{\Phi}:=\left[\begin{array}{c}{\boldsymbol{w}_{t}}\\ {\Delta_{\rho}y_{t-1}}\\ {\vdots}\\ {\Delta_{\rho}y_{t-k+2}}\end{array}\right]\qquad\mathbf{\Phi}\mathbf{v}_{t}:=\left[\begin{array}{c}{\alpha+u_{t}}\\ {0}\\ {\vdots}\\ {0}\end{array}\right]\qquad F_{\delta}(\psi):=\left[\begin{array}{c c c c c}{\psi_{1}\delta}&{\psi_{2}}&{\cdots}&{\psi_{k-2}}&{\psi_{k-1}}\\ {\delta}&{0}&{\cdots}&{0}&{0}\\ {0}&{1}&{}&{}&{}\\ &{\ddots}&{}&{}&{}\\ &&{1}&{}&{0}\end{array}\right]
$$  

where    $\psi:=(\psi_{1},.\,.\,.\,,\psi_{k-1})$  , we can write the companion form of (B.9)–(B.10) as  

$$
\pmb{w}_{t}=F_{\delta_{t-1}}(\psi)\pmb{w}_{t-1}+\pmb{v}_{t}
$$  

for    $t\in\{1,.\,.\,.\,,T\}$  , with the initialisation    $\pmb{w}_{0}:=(\Delta_{\rho}y_{0},\Delta_{\rho}y_{-1},.\,.\,.\,,\Delta_{\rho}y_{-k+2})^{\mathsf{T}}.$  .  

Since    $\psi\to\phi=\bigl(\phi_{1},.\,.\,,\phi_{k-1}\bigr)^{\mathsf{T}}$    as    $T\to\infty$  ,    $F_{\delta}(\pmb{\psi})\rightarrow F_{\delta}(\phi)=F_{\delta}$  , where    $F_{\delta}$   is as deﬁned in (3.5). By Proposition 1.8 in Jungers (2009) and the continuity of the JSR,  

$$
\lambda_{\mathrm{JSR}}(\{F_{\delta}(\psi)\mid\delta\in[0,1]\})=\lambda_{\mathrm{JSR}}(\{F_{0}(\psi),F_{1}(\psi)\})\to\lambda_{\mathrm{JSR}}(\{F_{0},F_{1}\})<1
$$  

under  A4 . It follows that there exists a norm    $\lVert\cdot\rVert_{*}$  and a    $\gamma\ \in\ [0,1)$   such that (for all    $\mathit{(I)}$  suﬃciently large),  

$$
\|\pmb{w}_{t}\|_{*}\leq\|F_{\delta_{t-1}}\|_{*}\|\pmb{w}_{t-1}\|_{*}+\|\pmb{v}_{t}\|_{*}\leq\gamma\|\pmb{w}_{t-1}\|_{*}+\|\pmb{v}_{t}\|_{*}
$$  

whence by backward substitution,  

$$
\|\pmb{w}_{t}\|_{*}\leq\sum_{s=0}^{t-1}\gamma^{s}\|\pmb{v}_{t-s}\|_{*}+\gamma^{t}\|\pmb{w}_{0}\|_{*}.
$$  

By the equivalence of norms on ﬁnite-dimensional spaces, there exists a    $C<\infty$  such that  

$$
|\Delta_{\rho}y_{t-1}|\leq C\left[\sum_{s=0}^{t-1}\gamma^{s}(|\alpha|+|u_{t-s}|)+\gamma^{t}\sum_{i=-k+2}^{0}|\Delta_{\rho}y_{i}|\right].
$$  

Deduce that for any    $p\geq1$  ,  

$$
\begin{array}{r l r}{\lefteqn{\|\Delta_{\rho}y_{t-1}\|_{p}\leq\frac{C|\alpha|}{1-\gamma}+C\sum_{s=0}^{t-1}\gamma^{s}\|u_{t-s}\|_{p}+C\sum_{i=-k+2}^{0}\|\Delta_{\rho}y_{i}\|_{p}}}\\ &{}&{\leq\frac{C|\alpha|}{1-\gamma}+\frac{C}{1-\gamma}\operatorname*{max}_{1\leq s\leq t}\|u_{s}\|_{p}+C\sum_{i=-k+2}^{0}\|\Delta_{\rho}y_{i}\|_{p}.}\end{array}
$$  

Now for  $i\in\{-k+2,.\,.\,.\,,0\}$  ,  $\begin{array}{r}{\Delta_{\rho}y_{i}=(1-\rho)[y_{0}-\sum_{j=i+1}^{0}\Delta y_{j}]+\rho\Delta y_{i}}\end{array}$  , and hence there   exists a  C  $C^{\prime}<\infty$   ∞ such that  

$$
\Vert\Delta_{\rho}y_{i}\Vert_{2+\delta_{u}}\leq C^{\prime}\left[\frac{1}{T^{1/2}}\Vert T^{-1/2}y_{0}\Vert_{2+\delta_{u}}+\frac{1}{T}\sum_{j=i+1}^{0}\Vert\Delta y_{j}\Vert_{2+\delta_{u}}+\Vert\Delta y_{i}\Vert_{2+\delta_{u}}\right],
$$  

where we have used that   $1-\rho=O(T^{-1})$  . Taking    $p=2+\delta_{u}$   in (B.11), it follows under  A3 that   $\mathrm{max}_{-k+2\leq t\leq T}\|\Delta_{\rho}y_{t}\|_{2+\delta_{u}}$   is bounded uniformly in    $T$  . To obtain the corresponding result for   $\Delta{y}_{t}$  , we use (B.6) with    $\mathit{\Omega}_{}^{\prime}/t=y_{t}$   to write  

$$
\Delta y_{t}=\Delta_{\rho}y_{t}+(\rho-1)y_{t-1}=\Delta_{\rho}y_{t}+(\rho-1)\left[\sum_{s=1}^{t-1}\rho^{t-1-s}\Delta_{\rho}y_{s}+\rho^{t-1}y_{0}\right]
$$  

whence there exists a    $C^{\prime\prime}<\infty$  such that  

$$
\|\Delta y_{t}\|_{2+\delta_{u}}\leq\|\Delta_{\rho}y_{t}\|_{2+\delta_{u}}+C^{\prime\prime}\left[T^{-1}\operatorname*{max}_{1\leq s\leq t}\|\Delta_{\rho}y_{s}\|_{2+\delta_{u}}+T^{-1/2}\|T^{-1/2}y_{0}\|_{2+\delta_{u}}\right],
$$  

from which, under  A3 , the result follows.  

Proof of Theorem 3.2.  When    $k=1$  , the result follows by Theorem 3.1; we therefore suppose  $k\geq2$  . We ﬁrst note that by (B.2) above,    $\rho^{\lfloor r T\rfloor}\,\rightarrow\,e^{c_{\phi}r}$    uniformly in    $r\,\in\,[0,1]$  . Hence for  $(x_{t},\xi_{t})$   as in Lemma B.1,  

$$
\begin{array}{l}{{:\displaystyle\left[x_{0}+\sum_{s=1}^{\lfloor r T\rfloor}\Delta\xi_{s}\right]=T^{-1/2}x_{0}+T^{-1/2}\xi_{\lfloor r T\rfloor}}}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {{\ }}\\ {\ }\\ {{\ }}\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {\ }\\ {
$$  

on    $D[0,1]$  , where    $\theta_{\phi}\;\;=\;\;(a,\phi(1)b_{0},\phi(1)^{-1}c),\;\;=_{(1)}$   holds since Lemma B.2 implies that  $\mathrm{max}_{0\le t\le T}|\Delta_{\rho}y_{t}|\,=\,o_{p}\bigl(T^{1/2}\bigr)$  , and  ${\xrightarrow{d}}_{(2)}$   holds by the same arguments as which yielded (A.1) above and by recalling that    $\psi(\rho^{-1})\to\phi(1)$  . Hence by Lemma B.1,    $x_{t}$   and    $v_{t}:=\Delta\xi_{t}$   satisfy the requirements of Lemma A.1. We thus have  

$$
\begin{array}{l l}{{T^{-1/2}y_{\lfloor r T\rfloor}=\psi(\rho^{-1})^{-1}\rho^{\lfloor r T\rfloor}T^{-1/2}x_{\lfloor r T\rfloor}}}\\ {{\ }}\\ {{\ \stackrel{d}{\to}\phi(1)^{-1}\mathrm{e}^{c_{\phi}r}\left\{K_{\theta_{\phi}}(r)+\underset{r^{\prime}\leq r}{\operatorname*{sup}}[-K_{\theta_{\phi}}(r^{\prime})]\right\}=\phi(1)^{-1}J_{\theta_{\phi}}(r)}}\end{array}
$$  

on    $D[0,1]$  .  

B.2. OLS asymptotics:   $\mathbf{AR}(k)$   case.  Since, by the implication of Assumption  A4 , all the roots  $\begin{array}{r}{\phi(z)=1-\sum_{i=1}^{k-1}\phi_{i}z^{i}}\end{array}$   lie strictly outside the unit circle, there exists a sequence    $\{\varphi_{i}\}_{i=0}^{\infty}$   $\varphi_{0}=1$   = 1 and    $\textstyle\sum_{0=1}^{\infty}\!\left|\varphi_{i}\right|<\infty$  P | |  ∞ s t    $\begin{array}{r}{\phi^{-1}(z):=\sum_{i=0}^{\infty}\varphi_{i}z^{i}}\end{array}$   satisﬁes    $\phi^{-1}(z)\phi(z)=1$   for all

  $|z|\leq1$  | | ≤ 1. Moreover, there exists a  $C<\infty$   ∞ and a  $\gamma_{\phi}\in(0,1)$   ∈  1) such that    $|\varphi_{i}|<C\gamma_{\phi}^{i}$    for all    $i\geq0$  .

 (See e.g., Brockwell and Davis (1991, Section 3.3).)  

Lemma B.3.  Let    $\begin{array}{r}{\phi_{m}^{-1}(z):=\sum_{i=0}^{m}\varphi_{i}z^{i}}\end{array}$   P , where    $m\geq1$  . Then there exists a    $C<\infty$  , independent of    $m$  , and    $\{d_{m,i}\}_{i=1}^{k-1}$    such that  

$$
\phi_{m}^{-1}(z)\phi(z)=1-z^{m}\sum_{i=1}^{k-1}d_{m,i}z^{i}=:1-d_{m}(z)z^{m}
$$  

for all    $|z|\leq1$   and    $m\in\mathbb{N}$  , and where    $|d_{m,i}|\leq C\gamma_{\phi}^{m}$  .  

Proof.  Since  

$$
1=\phi^{-1}(z)\phi(z)=\phi(z)\left[\phi_{m}^{-1}(z)+\sum_{i=m+1}^{\infty}\varphi_{i}z^{i}\right]
$$  

for    $|z|\leq1$  , it follows that  

$$
-\;\phi(z)\sum_{i=m+1}^{\infty}\varphi_{i}z^{i}=\phi(z)\phi_{m}^{-1}(z)=\left(1-\sum_{i=1}^{k-1}\phi_{i}z^{i}\right)\sum_{i=0}^{m}\varphi_{i}z^{i}=:1-\sum_{i=1}^{m+k-1}\vartheta_{m,i}z^{i},
$$  

using that    $\varphi_{0}=1$  . Matching coeﬃcients on the left and right hand sides, we obtain    $\vartheta_{m,i}=0$   $i\in\{1,.\,.\,.\,,m\}$   $i\in\{m+1,.\,.\,.\,,m+k-1\}$  ,    $\begin{array}{r}{\vartheta_{m,i}=\sum_{j=0}^{i-(m+1)}\phi_{j}\varphi_{i-j}}\end{array}$  . Taking  $\begin{array}{r}{d_{m,i}:=\vartheta_{m,m+i}=\sum_{j=0}^{i-1}\phi_{j}\varphi_{m+i-j}}\end{array}$   for  i  $i\in\{1,.\,.\,.\,,k-1\}$   ∈{  − } , and noting that  

$$
|d_{m,i}|\leq\sum_{j=i}^{k-1}|\phi_{j}||\varphi_{m+i-j}|\leq C\gamma_{\phi}^{m}\sum_{j=1}^{k-1}|\phi_{j}|
$$  

yields the result.  

Lemma B.4.  Suppose Assumptions  A1 – A4  hold. Then for each    $s\in\{0,.\,.\,.\,,k-1\}$  ,  

(i)    $\begin{array}{r}{T^{-1/2}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})\xrightarrow{d}\phi(1)[Y_{\theta_{\phi}}(1)-c_{\phi}\int Y_{\theta_{\phi}}(r)-b_{0}]-a;}\end{array}$  R (ii)  ${\textstyle\sum_{t=1}^{T}(y_{t}^{-})^{2}=o_{p}(T)}$  ;  

$$
\begin{array}{r l}&{T^{-1}\sum_{t=1}^{T}\Delta y_{t}\Delta y_{t-s}\xrightarrow{p}\sigma^{2}\sum_{n=0}^{\infty}\varphi_{n}\varphi_{n+s};~a n d}\\ &{\sum_{t=1}^{T}y_{t}\Delta y_{t-s}=O_{p}(T).}\end{array}
$$  

Proof.  (i).  Applying the factorisation (B.1) to (2.6), we get  

$$
u_{t}-y_{t}^{-}=-\alpha-(\beta-1)y_{t-1}+\phi(L)\Delta y_{t}
$$  

and hence, recalling that    $\begin{array}{r}{\phi(1)=1-\sum_{i=1}^{k-1}\phi_{i}}\end{array}$  ,    $\alpha=T^{1/2}a$  , and    $T(\beta-1)\rightarrow c$   under  A2 ,  

$$
\begin{array}{c}{\displaystyle\frac{1}{T^{1/2}}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})=-a-\frac{T(\beta-1)}{T^{3/2}}\sum_{t=1}^{T}y_{t-1}+\frac{1}{T^{1/2}}\left(\sum_{t=1}^{T}\Delta y_{t}-\sum_{i=1}^{k-1}\phi_{i}\sum_{t=1}^{T}\Delta y_{t}\right.}\\ {\displaystyle=-a-\frac{T(\beta-1)}{T^{3/2}}\sum_{t=1}^{T}y_{t-1}+\frac{y_{T}-y_{0}}{T^{1/2}}-\sum_{i=1}^{k-1}\phi_{i}\frac{y_{T-i}-y_{0-i}}{T^{1/2}}}\\ {\displaystyle\stackrel{d}{\to}-a-c\int_{0}^{1}Y_{\theta_{\phi}}(r)\,\mathrm{d}r+\phi(1)[Y_{\theta_{\phi}}(1)-b_{0}]}\\ {\displaystyle=\phi(1)\left[Y_{\theta_{\phi}}(1)-c_{\phi}\int_{0}^{1}Y_{\theta_{\phi}}(r)\,\mathrm{d}r-b_{0}\right]-a,}\end{array}
$$  

where convergence holds by Assumption  A1 , Theorem 3.2 and the CMT, recalling that    $c_{\phi}=$   $\phi(1)^{-1}c$  .  

(ii). The argument is analogous to that used to prove Lemma A.2(ii). Rewriting the factorisation (B.1) as  

$$
\beta z+(1-z)\sum_{i=1}^{k-1}\phi_{i}z^{i}=1-(1-\rho z)\left[1-\sum_{i=1}^{k-1}\psi_{i}z^{i}\right]=\rho z+\sum_{i=1}^{k-1}\psi_{i}z^{i}(1-\rho z)
$$  

we have from (2.6) that  

$$
-1+\sum_{i=1}^{k-1}\phi_{i}\Delta y_{t-i}+\alpha+u_{t}\Bigg]_{-}=\Bigg[\rho y_{t-1}+\sum_{i=1}^{k-1}\psi_{i}\Delta_{\rho}y_{t-i}+\alpha+u_{t}\Bigg]_{-}=[\rho y_{t-1}+v_{t}]
$$  

where    $\begin{array}{r}{v_{t}:=\sum_{i=1}^{k-1}\psi_{i}\Delta_{\rho}y_{t-i}+\alpha+u_{t}}\end{array}$  . Since    $\rho y_{t-1}\geq0$  , it follows that −  

$$
0\geq y_{t}^{-}=(\rho y_{t-1}+v_{t})\mathbf{1}\{\rho y_{t-1}+v_{t}\leq0\}\geq v_{t}\mathbf{1}\{\rho y_{t-1}+v_{t}\leq0\}.
$$  

By Lemma B.2,    $\lVert\Delta_{\rho}y_{t}\rVert_{2+\delta_{u}}$   is bounded uniformly in    $t$  . Hence, under  A3 , so too is  

$$
\|v_{t}\|_{2+\delta_{u}}\leq\sum_{i=1}^{k-1}\lvert\psi_{i}\rvert\|\Delta_{\rho}y_{t-i}\|_{2+\delta_{u}}+\lvert\alpha\rvert+\|u_{t}\|_{2+\delta_{u}}.
$$  

whence it follows that   $\begin{array}{r}{\operatorname*{max}_{1\le t\le T}\bigl|y_{t}^{-}\bigr|\,\le\,\operatorname*{max}_{1\le t\le T}\bigl|v_{t}\bigr|\,=\,o_{p}\bigl(T^{1/2}\bigr)}\end{array}$    ). Hence, using the result of ≤ ≤ part (i),  

$$
\sum_{t=1}^{T}(y_{t}^{-})^{2}\leq\operatorname*{max}_{1\leq t\leq T}\bigl|y_{t}^{-}\bigr|\sum_{t=1}^{T}\bigl|y_{t}^{-}\bigr|=-\operatorname*{max}_{1\leq t\leq T}\bigl|y_{t}^{-}\bigr|\sum_{t=1}^{T}y_{t}^{-}
$$  

$$
=-\operatorname*{max}_{1\leq t\leq T}\lvert y_{t}^{-}\rvert\left(\sum_{t=1}^{T}u_{t}+O_{p}(T^{1/2})\right)=o_{p}(T).
$$  

(iii).  Let    $s\in\{0,.\,.\,.\,,k-1\}$  . By Lemma B.3, applying    $\begin{array}{r}{\phi_{t-1}^{-1}(L)=\sum_{i=0}^{t-1}\varphi_{i}L^{i}}\end{array}$   P  to both sides − of (B.13) yields  

$$
\Delta y_{t}-d_{t-1}(L)\Delta y_{1}=\phi_{t-1}^{-1}(L)\phi(L)\Delta y_{t}=\sum_{i=0}^{t-1}\varphi_{i}L^{i}[(\beta-1)y_{t-1}+\alpha+u_{t}-y_{t}^{-}]
$$  

and hence for    $t\in\{1,.\,.\,.\,,T\}$  ,  

$$
\begin{array}{r l r}{\lefteqn{\Delta y_{t}=\sum_{i=0}^{t-1}\varphi_{i}(\alpha+u_{t-i})+(\beta-1)\sum_{i=0}^{t-1}\varphi_{i}y_{t-1-i}-\sum_{i=0}^{t-1}\varphi_{i}y_{t-i}^{-}+d_{t-1}(L)\Delta y_{1}}}\\ &{}&{=:w_{t}+r_{1,t}+r_{2,t}+r_{3,t}.}\end{array}
$$  

Decompose  

$$
\gamma_{t}=\sum_{i=0}^{t-1}\varphi_{i}(\alpha+u_{t-i})=\sum_{i=0}^{\infty}\varphi_{i}u_{t-i}-\sum_{i=t}^{\infty}\varphi_{i}u_{t-i}+\frac{a}{T^{1/2}}\sum_{i=0}^{t-1}\varphi_{i}=:\eta_{t}+r_{4,t}+r_{5,t}.
$$  

The sequence    $\{\eta_{t}\}$   is a stationary linear process whose coeﬃcients decay exponentially; hence by Phillips and Solo (1992, Thm. 3.7 and Rem. 3.9),  

$$
\frac{1}{T}\sum_{t=s+1}^{T}\eta_{t}\eta_{t-s}\xrightarrow{p}\sigma^{2}\sum_{n=0}^{\infty}\varphi_{n}\varphi_{n+s}.
$$  

Since for all    $i$  ,    $|\varphi_{i}|<C\gamma_{\phi}^{i}$  ,    $\gamma_{\phi}\in(0,1)$  , we have  

$$
;\sum_{t=1}^{T}r_{4,t}^{2}\Bigg]=\frac{\sigma^{2}}{T}\sum_{t=1}^{T}\sum_{i=t}^{\infty}\varphi_{i}^{2}=O(T^{-1}),\;\;\;\;\;\frac{1}{T}\sum_{t=1}^{T}r_{5,t}^{2}=\frac{a^{2}}{T^{2}}\sum_{t=1}^{T}\left(\sum_{i=0}^{t-1}\varphi_{i}\right)^{2}=O(T^{-1}).
$$  

It follows by the CS inequality that  $\begin{array}{r}{\frac{1}{T}\sum_{t=s+1}^{T}(\eta_{t}r_{\ell,t-s}+\eta_{t-s}r_{\ell,t})\,=\,o_{p}(1)}\end{array}$  P (1) for    $\ell\,\in\,\{4,5\}$   and  $\begin{array}{r}{\frac{1}{T}\sum_{t=s+1}^{T}r_{\ell,t}r_{\ell^{\prime},t-s}=o_{p}(1)}\end{array}$  (1) for    $\ell,\ell^{\prime}\in\{4,5\}$  , and hence −  

$$
\frac{1}{T}\sum_{t=s+1}^{T}w_{t}w_{t-s}=\frac{1}{T}\sum_{t=s+1}^{T}\eta_{t}\eta_{t-s}+o_{p}(1)\xrightarrow{p}\sigma^{2}\sum_{n=0}^{\infty}\varphi_{n}\varphi_{n+s}
$$  

for each    $s\in\{0,.\,.\,.\,,k-1\}$  . Thus, if we can show that  

$$
\sum_{t=1}^{T}r_{1,t}^{2}=O_{p}(1)\qquad\qquad\sum_{t=1}^{T}r_{2,t}^{2}=o_{p}(T)\qquad\qquad\sum_{t=1}^{T}r_{3,t}^{2}=O_{p}(1).
$$  

it will follow that  

$$
\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t}\Delta y_{t-s}=_{(1)}\frac{1}{T}\sum_{t=s+1}^{T}\Delta y_{t}\Delta y_{t-s}+o_{p}(1)
$$  

$$
\mathbf{\Sigma}=_{(2)}\frac{1}{T}\sum_{t=s+1}^{T}w_{t}w_{t-s}+o_{p}(1)\xrightarrow[]{p}_{(3)}\sigma^{2}\sum_{n=0}^{\infty}\varphi_{n}\varphi_{n+s}.
$$  

where   $\overline{{\overline{{\mathbf{\alpha}}}}}(1)$   holds by Lemma B.2,   $\overline{{\overline{{\mathbf{\alpha}}}}}(2)$   by (B.14)–(B.16) and the CS inequality, and  $\xrightarrow{p}_{(3)}$  →  by (B.15).  

It remains to prove (B.16). Since    $\beta-1=O(T^{-1})$  , there exists a    $C<\infty$  such that  

$$
|r_{1,t}|\leq\frac{C}{T}\sum_{i=0}^{t-1}|\varphi_{i}||y_{t-1-i}|\leq\left(\sum_{i=0}^{\infty}|\varphi_{i}|\right)\frac{C}{\sqrt{T}}\operatorname*{max}_{0\leq t\leq T-1}\left|y_{t}/\sqrt{T}\right|=O_{p}(T^{-1/2})
$$  

uniformly in    $t$   by Theorem 3.2; the ﬁrst part of (B.16) follows immediately. Next,  

$$
\begin{array}{c}{{\displaystyle\sum_{t=1}^{T}r_{2,t}^{2}=\displaystyle\sum_{t=1}^{T}\left(\sum_{i=0}^{t-1}\varphi_{i}y_{t-i}^{-}\right)^{2}=\displaystyle\sum_{t=1}^{T}\sum_{i=0}^{t-1}\sum_{j=0}^{t-1}\varphi_{i}\varphi_{j}y_{t-i}^{-}y_{t-j}^{-}}}\\ {{=\displaystyle\sum_{i=0}^{T}\sum_{j=0}^{T}\varphi_{i}\varphi_{j}\sum_{t=\operatorname*{max}\{i,j\}+1}^{T}y_{t-i}^{-}y_{t-j}^{-}=o_{p}(T)}}\end{array}
$$  

by  $\textstyle\sum_{i=0}^{\infty}\!\left|\varphi_{i}\right|<\infty$   ∞ , the result of part (ii), and the CS inequality. Finally, by Lemma B.3,  

$$
\sum_{t=1}^{T}r_{3,t}^{2}=\sum_{t=1}^{T}\left(\sum_{i=1}^{k-1}d_{t-1,i}\Delta y_{1-i}\right)^{2}\leq C^{2}\left(\sum_{i=1}^{k-1}\lvert\Delta y_{1-i}\rvert\right)^{2}\sum_{t=1}^{T}\gamma_{\phi}^{2(t-1)}=O_{p}(1).
$$  

(iv).  We ﬁrst note that since  $\textstyle a b={\frac{1}{2}}((a+b)^{2}-a^{2}-b^{2})$  ,  

$$
\sum_{t=1}^{T}y_{t-1}\Delta y_{t}=\frac{1}{2}\sum_{t=1}^{T}(y_{t}^{2}-y_{t-1}^{2}-(\Delta y_{t})^{2})=\frac{1}{2}\left\{y_{T}^{2}-y_{0}^{2}-\sum_{t=1}^{T}(\Delta y_{t})^{2}\right\}
$$  

which is    $O_{p}(T)$   by Theorem 3.2 and part (iii) of this lemma. This gives the result when    $s=1$  . To obtain the result for general    $s\in\{0,.\,.\,.\,,k-1\}$  , we simply note that  

$$
\sum_{t=1}^{T}y_{t}\Delta y_{t}=\sum_{t=1}^{T}(\Delta y_{t})^{2}+\sum_{t=1}^{T}y_{t-1}\Delta y_{t}
$$  

and  

$$
\sum_{t=1}^{T}y_{t-s}\Delta y_{t}=\sum_{t=1}^{T}\left(y_{t}-\sum_{r=0}^{s-1}\Delta y_{t-r}\right)\Delta y_{t}=\sum_{t=1}^{T}y_{t}\Delta y_{t}-\sum_{r=0}^{s-1}\sum_{t=1}^{T}\Delta y_{t}\Delta y_{t-r}
$$  

when    $s\geq1$  ; the result then follows by a further appeal to part (iii) of this lemma.  

Proof of Theorem 3.4.  Let    $\pmb{y}_{t}:=(y_{t},y_{t-1},.\cdot.\,.\,,y_{t-k+2})^{\mathsf{T}}$    and deﬁne  

$$
\boldsymbol{M}_{T}:=\sum_{t=1}^{T}\left[\begin{array}{c c c}{1}&{\boldsymbol{y}_{t-1}}&{\Delta\pmb{y}_{t-1}^{\intercal}}\\ {\boldsymbol{y}_{t-1}}&{\boldsymbol{y}_{t-1}^{2}}&{\boldsymbol{y}_{t-1}\Delta\pmb{y}_{t-1}^{\intercal}}\\ {\Delta\pmb{y}_{t-1}}&{\boldsymbol{y}_{t-1}\Delta\pmb{y}_{t-1}}&{\Delta\pmb{y}_{t-1}\Delta\pmb{y}_{t-1}^{\intercal}}\end{array}\right]\qquad\boldsymbol{m}_{T}:=\sum_{t=1}^{T}\left[\begin{array}{c}{1}\\ {\boldsymbol{y}_{t-1}}\\ {\Delta\pmb{y}_{t-1}}\end{array}\right](\boldsymbol{u}_{t}-\boldsymbol{y}_{t-1}).
$$  

Then by rewriting (2.5) as  

$$
y_{t}=\alpha+\beta y_{t-1}+\phi^{\mathsf{T}}\Delta\pmb{y}_{t-1}+u_{t}-y_{t}^{-},
$$  

the centred and rescaled OLS estimators   $\hat{\mu}_{T}^{\sf T}:=(\hat{\alpha}_{T},\hat{\beta}_{T},\hat{\phi}_{T}^{\sf T})$  ) of    ${\boldsymbol{\mu}}^{\mathsf{T}}=(\alpha,\beta,\phi^{\mathsf{T}})$   are equal to  

$$
\begin{array}{r}{\left[\begin{array}{c}{T^{1/2}(\hat{\alpha}_{T}-\alpha)}\\ {T(\hat{\beta}_{T}-\beta)}\\ {\hat{\phi}_{T}-\phi}\end{array}\right]=D_{2,T}(\hat{\mu}_{T}-\mu)=(D_{1,T}^{-1}\mathcal{M}_{T}D_{2,T}^{-1})^{-1}D_{1,T}^{-1}m_{T}}\end{array}
$$  

where  D  $D_{1,T}:=\mathrm{diag}\{T^{1/2},T,I_{k-1}T\},\,D_{2,T}:=\mathrm{diag}\{T^{1/2},T,I_{k-1}\},$  

$$
D_{1,T}^{-1}\mathcal{M}_{T}D_{2,T}^{-1}=\left[\begin{array}{c c c}{1}&{T^{-3/2}\sum_{t=1}^{T}y_{t-1}}&{T^{-1/2}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}^{\top}}\\ {T^{-3/2}\sum_{t=1}^{T}y_{t-1}}&{T^{-2}\sum_{t=1}^{T}y_{t-1}^{2}}&{T^{-1}\sum_{t=1}^{T}y_{t-1}\Delta\pmb{y}_{t-1}^{\top}}\\ {T^{-3/2}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}}&{T^{-2}\sum_{t=1}^{T}y_{t-1}\Delta\pmb{y}_{t-1}}&{T^{-1}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}\Delta\pmb{y}_{t-1}^{\top}}\end{array}\right]
$$  

and  

$$
D_{1,T}^{-1}m_{T}=\left[\begin{array}{c}{T^{-1/2}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})}\\ {T^{-1}\sum_{t=1}^{T}y_{t-1}(u_{t}-y_{t}^{-})}\\ {T^{-1}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}(u_{t}-y_{t}^{-})}\end{array}\right].
$$  

It remains to determine the weak limits of the elements of (B.18) and (B.19). We consider (B.18) ﬁrst. By Theorem 3.2 and the CMT,  

$$
\begin{array}{r}{\gamma_{T}:=\left[\begin{array}{c c}{1}&{T^{-3/2}\sum_{t=1}^{T}y_{t-1}}\\ {T^{-3/2}\sum_{t=1}^{T}y_{t-1}}&{T^{-2}\sum_{t=1}^{T}y_{t-1}^{2}}\end{array}\right]\overset{d}{\to}\left[\begin{array}{c c}{1}&{\int Y_{\theta_{\phi}}(r)\,\mathrm{d}r}\\ {\int Y_{\theta_{\phi}}(r)\,\mathrm{d}r}&{\int Y_{\theta_{\phi}}^{2}(r)\,\mathrm{d}r}\end{array}\right]=:\mathcal{Y}_{\theta_{\phi}}.}\end{array}
$$  

By Theorem 3.2 and Lemma B.4(iv),  

$$
\Xi_{T}:=\left[\!\!\begin{array}{c c c c}{T^{-1/2}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}^{\mathsf{T}}}\\ {T^{-1}\sum_{t=1}^{T}y_{t-1}\Delta\pmb{y}_{t-1}^{\mathsf{T}}}\end{array}\!\!\right]=\left[\!\!\begin{array}{c c c c}{T^{-1/2}(\pmb{y}_{T-1}-\pmb{y}_{-1})^{\mathsf{T}}}\\ {T^{-1}\sum_{t=1}^{T}y_{t-1}\Delta\pmb{y}_{t-1}^{\mathsf{T}}}\end{array}\!\!\right]=O_{p}(1).
$$  

By Lemma B.4(iii),  

$$
\Omega_{T}:=T^{-1}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}\Delta\pmb{y}_{t-1}^{\intercal}\xrightarrow{p}\Omega
$$  

where   $\begin{array}{r}{\Omega_{i j}:=\sigma^{2}\sum_{n=0}^{\infty}\varphi_{n}\varphi_{n+|i-j|}}\end{array}$  . It follows by the partitioned matrix inversion formula and | − | the continuity of matrix inversion that  

$$
(D_{1,T}^{-1}\mathcal{M}_{T}D_{2,T}^{-1})^{-1}=\left[\begin{array}{l l}{\mathcal{Y}_{T}}&{\Xi_{T}}\\ {o_{p}(1)}&{\Omega_{T}}\end{array}\right]^{-1}=\left[\begin{array}{l l}{\mathcal{Y}_{T}^{-1}}&{-\mathcal{Y}_{T}^{-1}\Xi_{T}\Omega_{T}^{-1}}\\ {0}&{\Omega_{T}^{-1}}\end{array}\right]+o_{p}(1).
$$  

We turn next to (B.19). By Lemma B.4(i),  

$$
\mathcal{Z}_{T}^{(\alpha)}:=\frac{1}{T^{1/2}}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})\to\phi(1)\left[Y_{\theta_{\phi}}(1)-c_{\phi}\int_{0}^{1}Y_{\theta_{\phi}}(r)\,\mathrm{d}r-b_{0}\right]-a:=\mathcal{Z}_{\theta_{\phi}}^{(\alpha)}.
$$  

Next, since only one of    $y_{t}$   and    $y_{t}^{-}$    can be nonzero,    $y_{t-1}y_{t}^{-}=-\Delta y_{t}y_{t}^{-}$   − , and hence  

$$
\begin{array}{l}{\mathbf{\Sigma}_{T}^{(\beta)}:=\displaystyle\frac{1}{T}\sum_{t=1}^{T}y_{t-1}(u_{t}-y_{t}^{-})=\displaystyle\frac{1}{T}\sum_{t=1}^{T}y_{t-1}u_{t}+\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t}y_{t}^{-}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}_{T}^{(\beta)}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\\ {\mathbf{\Sigma}}\end{array}
$$  

where  ${\xrightarrow{d}}_{(2)}$   holds by Theorem 3.2 and Liang  et al.  (2016, Theorem 2.1), and   $\overline{{\overline{{\mathbf{\alpha}}}}}(1)$   since  

$$
\left|\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t}y_{t}^{-}\right|^{2}\leq\frac{1}{T}\sum_{t=1}^{T}(\Delta y_{t})^{2}\frac{1}{T}\sum_{t=1}^{T}(y_{t}^{-})^{2}=o_{p}(1)
$$  

by the CS inequality and Lemma B.4(ii)–(iii). Finally, for    $s\in\{1,.\,.\,.\,,k-1\}$  ,  

$$
\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}(u_{t}-y_{t}^{-})=\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}u_{t}-\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}y_{t}^{-}=\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}u_{t}+o_{p}(
$$  

by the same argument as which yielded (B.26). Further, by Lemma B.2,  

$$
\mathbb{E}\left(\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}u_{t}\right)^{2}=\frac{\sigma^{2}}{T^{2}}\sum_{t=1}^{T}\mathbb{E}(\Delta y_{t-s})^{2}=O(T^{-1}).
$$  

Hence  

$$
\frac{1}{T}\sum_{t=1}^{T}\Delta y_{t-s}(u_{t}-y_{t}^{-})=O_{p}(T^{-1/2})+o_{p}(1)=o_{p}(1).
$$  

$\mathcal{Z}_{T}:=(\mathcal{Z}_{T}^{(\alpha)},\mathcal{Z}_{T}^{(\beta)})^{\mathsf{T}}$   and  $\mathcal{Z}_{\boldsymbol{\theta}_{\phi}}:=(\mathcal{Z}_{\boldsymbol{\theta}_{\phi}}^{(\alpha)},\mathcal{Z}_{\boldsymbol{\theta}_{\phi}}^{(\beta)})^{\mathsf{T}}$  Letting    Z   , it follows from (B.19), (B.24), (B.25) and (B.27) that  

$$
D_{1,T}^{-1}m_{T}=\left[\mathcal{Z}_{T}\atop o_{p}(1)\right]\stackrel{d}{\to}\left[\mathcal{Z}_{\theta_{\phi}}\atop0\right].
$$  

Therefore, recalling (B.17), and using (B.20)–(B.23), we obtain  

$$
\begin{array}{r l}&{D_{2,T}(\hat{\mu}_{T}-\mu)=\left(\left[\mathcal{Y}_{T}^{-1}\!\begin{array}{c}{-\mathcal{Y}_{T}^{-1}\Xi_{T}\Omega_{T}^{-1}}\\ {0}\end{array}\right]+o_{p}(1)\right)\left[\mathcal{Z}_{T}\right]}\\ &{\qquad\qquad=\left[\mathcal{Y}_{T}^{-1}\mathcal{Z}_{T}\right]+o_{p}(1)\overset{d}{\to}\left[\mathcal{Y}_{\theta_{\phi}}^{-1}\mathcal{Z}_{\theta_{\phi}}\right].}\end{array}
$$  

Proof of Corollary 3.2 (  $\mathit{\Omega}_{k}\geq2\;\;$  ).  We ﬁrst show that   $\hat{\sigma}_{T}^{2}\ \xrightarrow{p}\ \sigma^{2}$  → . Adapting the argument from the    $k=1$   case, we have  

$$
\sum_{t=1}^{T}[\hat{u}_{t}^{2}-(u_{t}-y_{t}^{-})^{2}]=\sum_{t=1}^{T}[(\alpha-\hat{\alpha}_{T})+(\beta-\hat{\beta}_{T})y_{t-1}+(\phi-\hat{\phi}_{T})^{\mathsf{T}}\Delta\mathbf{y}_{t-1}][\hat{u}_{t}+(u_{t}-y_{t}^{-})^{2}].
$$  

$$
\begin{array}{r l}{\lefteqn{=\big(\alpha-\hat{\alpha}_{T}\big)\sum_{t=1}^{T}(u_{t}-y_{t}^{-})+\big(\beta-\hat{\beta}_{T}\big)\sum_{t=1}^{T}y_{t-1}\big(u_{t}-y_{t}^{-}\big)}}\\ &{\leq\qquad\qquad+\left(\phi-\hat{\phi}_{T}\right)^{\mathsf{T}}\sum_{t=1}^{T}\Delta\pmb{y}_{t-1}\big(u_{t}-y_{t}^{-}\big)}\\ &{=O_{p}(T^{-1/2})O_{p}(T^{1/2})+O_{P}(T^{-1})O_{p}(T)+o_{p}(1)o_{p}(T)=o_{p}(T)}\end{array}
$$  

where the the orders of the sums follow from Lemma B.4(i), (B.25) and (B.27), and the rates of convergence of the OLS estimators from Theorem 3.4. It follows that  

$$
\frac{1}{T}\sum_{t=1}^{T}\hat{u}_{t}^{2}=\frac{1}{T}\sum_{t=1}^{T}(u_{t}-y_{t}^{-})^{2}+o_{p}(1)=\frac{1}{T}\sum_{t=1}^{T}u_{t}^{2}+o_{p}(1)\stackrel{p}{\rightarrow}\sigma^{2}
$$  

by Lemma B.4(ii), the LLN and the CS inequality. To complete the proof, we note that since    $\phi(1)^{-1}J_{\theta_{\phi}}(r)=Y_{\theta_{\phi}}(r)$  ,  

$$
\begin{array}{r l}&{\mathcal{Y}_{\theta_{\phi}}=\left[\begin{array}{c c}{1}&{\int_{0}^{1}Y_{\theta_{\phi}}(r)\,\mathrm{d}r}\\ {\int_{0}^{1}Y_{\theta_{\phi}}(r)\,\mathrm{d}r}&{\int_{0}^{1}Y_{\theta_{\phi}}^{2}(r)\,\mathrm{d}r}\end{array}\right]}\\ &{\quad=\left[\begin{array}{c c}{1}&{0}\\ {0}&{\phi(1)^{-1}}\end{array}\right]\left[\begin{array}{c c}{1}&{\int_{0}^{1}J_{\theta_{\phi}}(r)\,\mathrm{d}r}\\ {\int_{0}^{1}J_{\theta_{\phi}}(r)\,\mathrm{d}r}&{\int_{0}^{1}J_{\theta_{\phi}}^{2}(r)\,\mathrm{d}r}\end{array}\right]\left[\begin{array}{c c}{1}&{0}\\ {0}&{\phi(1)^{-1}}\end{array}\right].}\end{array}
$$  

It follows that the result of Theorem 3.4 can be rewritten as  

$$
\begin{array}{r}{\bigg[T^{1/2}(\hat{\alpha}_{T}-\alpha)\bigg]\xrightarrow{d}\bigg[\phi(1)\mathfrak{b}_{\theta_{\phi}}\bigg]}\\ {T(\hat{\beta}_{T}-\beta)\bigg]d\theta\bigg[\phi(1)\mathfrak{b}_{\theta_{\phi}}\bigg].}\end{array}
$$  

By (B.20) and (B.23), the upper left   $2\times2$   block of    $D_{1,T}^{-1}\mathcal{M}_{T}D_{2,T}^{-1}$    converges to    $\mathcal{Y}_{\theta_{\phi}}$  . Thus,  $D_{2,T}\mathbf{\mathcal{M}}_{T}^{-1}D_{1,T}$   converges to    $\mathcal{Y}_{\theta_{\phi}}^{-1}$  , and so    $T\mathcal{M}_{T}^{-1}(1,1)\ \stackrel{d}{\to}\ \mathcal{I}_{\theta_{\phi}}^{-1}(1,1)$   1) and    $T^{2}\mathcal{M}_{T}^{-1}(2,2)\ \xrightarrow{a_{\sqrt{}}}$  →  $\phi(1)^{2}\mathcal{I}_{\theta_{\phi}}^{-1}(2,2)$   2). Hence, the result follows by the CMT. □  

# Appendix C. Role of the joint spectral radius  

Example 1  (Stationary roots of    $\phi(z)$   are not suﬃcient for Theorem 3.2) .  Let    $\beta=1$   and  

$$
B(z)=(1-z)\phi(z),\quad\phi(z)=(1-z+0.9z^{2})(1-1.3z+0.9z^{2}).
$$  

The roots of    $\phi(z)$   are larger than   $1$   in absolute value (roots are approximately   $0.56\pm0.9i$  and   $0.7\pm0.77i$  ). However, simulations in Figure C.1 indicate that    $\{\Delta y_{t}\}$   is not stochastically bounded and    $\{y_{t}\}$   grows exponentially, preventing the result of Theorem 3.2 from holding.  

Example 2  (Assumption  A4  is not necessary for Theorem 3.2) .  Let  

$$
B(z)=(1-z)\phi(z),\quad\phi(z)=1-1.3z+0.8z^{2}.
$$  

  
(a)  The rescaled by  $\sqrt{T}$  √  process explodes.  

  

  
(b)  First diﬀerences are not bounded.  

  
(b)  First diﬀerences are bounded.  

That is,    $k=3$  ,    $\beta=1$  ,    $\phi_{1}=1.3\$   and    $\phi_{2}=-0.8$  . The roots of    $\phi(z)$   are larger than 1 in absolute value (roots are approximately   $0.8\pm0.77i$  ). However, the largest (in modulus) eigenvalue of  $F_{1}F_{1}F_{0}$   is    $-1.04$  , and so    $\lambda_{\mathrm{JSR}}(\{F_{0},F_{1}\})\,\geq\,|-1.04|^{1/3}\,>\,1$  . On the other hand, simulations in Figure C.2 indicate that    $\{\Delta y_{t}\}$   is stochastically bounded. Thus, Assumption  A4  is not necessary for Theorem 3.2.  

Proof of Lemma 3.1.  Let    $\textstyle\sum_{i=1}^{k-1}|\phi_{i}|\;=\;\Phi\;<\;1$    | |    $\begin{array}{r}{M\,\in\,\mathcal{A}^{n}\,=\,\{\prod_{j=1}^{n}A_{i}\,\mid\,A_{j}\,\in\,\{F_{0},F_{1}\}\}}\end{array}$   |  ∈{ . Let us show that the spectral radius of  M ,  $\lambda(M)$  ), is at most Φ  $\Phi^{\lfloor n/(k-1)\rfloor}$  , where    $\lfloor\cdot\rfloor$  is a ﬂoor function. Then,  

$$
\lambda_{\operatorname{JSR}}(\{F_{0},F_{1}\})=\operatorname*{lim}_{n\to\infty}\operatorname*{sup}_{M\in\mathcal{A}^{n}}\lambda(M)^{1/n}\leq\operatorname*{lim}_{n\to\infty}\left(\Phi^{\left\lfloor\frac{n}{k-1}\right\rfloor}\right)^{1/n}=\Phi^{\frac{1}{k-1}}<1.
$$  

First, suppose    $n=k-1$  , so that    $M=F_{\delta_{k-1}}\cdot.\,.\,.\,F_{\delta_{1}}$  ,  where    $\delta_{j}\in\{0,1\}$  ,   $j=1,.\,.\,.\,,k-1$  . Let us show that for any vector    $x\;=\;(x_{1},.\,.\,.\,,x_{k-1})^{\mathsf{T}}\;\in\;\mathbb{R}^{k-1}$  ,    $\|M x\|_{\infty}\;\leq\;\Phi\|x\|_{\infty}$  , where

  $\|x\|_{\infty}:=\operatorname*{max}_{i=1,\ldots,k-1}\{|x_{i}|\}$  , i.e. the maximum norm    $\ell_{\infty}$  . Let    $x^{s}:=F_{\delta_{s}}\cdot.\ .\ .\ F_{\delta_{1}}x$  ,    $s=1,.\,.\,.\,,k-1$  .  

We prove by induction that for any    $s\,=\,1,.\,.\,.\,,k\,-\,1$  ,    $|x_{i}^{s}|\,\leq\,\Phi\|x\|_{\infty}$  | ≤ ∥ ∥ for    $i\,=\,1,.\,.\,.\,,s$   and ∞

  $|x_{i}^{s}|\leq\|x\|_{\infty}$  | ≤∥ ∥ for    $i>s$  . To verify induction base, note that since ∞  

$$
F_{\delta}\boldsymbol{x}=\left(\delta\phi_{1}x_{1}+\sum_{i=2}^{k-1}\phi_{i}x_{i},\,\delta x_{1},\,x_{2},\,.\,.\,,x_{k-2}\right)^{\mathsf{T}},
$$  

$|x_{1}^{1}|\,\leq\,\Phi\|x\|_{\infty}$  | ≤ ∥ ∥ and    $|x_{i}^{1}|\,\leq\,|x_{i-1}|\,\leq\,\|x\|_{\infty}$    | ≤| | ≤∥ ∥ for    $\textit{i}>1$  . To verify induction step, suppose that ∞ − ∞ the claim holds for    $s$   and let us prove it for    $s+1$  . Using    $x^{s+1}\,=\,F_{\delta_{s+1}}x^{s}$    and (C.1), we get

  $|x_{1}^{s+1}|\leq\Phi\|x^{s}\|_{\infty}\leq\Phi\|x\|_{\infty}$  | ≤ ∥ ∥ ≤ ∥ ∥ , where the last inequality follows from induction hypothesis. Next, ∞ ∞

  $|x_{2}^{s+1}|=|\delta x_{1}^{s}|\leq|x_{1}^{s}|\leq\Phi\|x\|_{\infty}$  |  | | ≤| | ≤ ∥ ∥ and for    $i>2$   we have    $|x_{i}^{s+1}|=|x_{i-1}^{s}|$  | . Thus, for    $i>s+1$   we ∞ − have    $|x_{i}^{s+1}|=|x_{i-1}^{s}|\leq\|x\|_{\infty}$  |  | | ≤∥ ∥ , while for   $2<i\leq s+1$  ,    $|x_{i}^{s+1}|=|x_{i-1}^{s}|\leq\Phi\|x\|_{\infty}$  |  | | ≤ ∥ ∥ . − ∞ − ∞  

It follows from the preceding that since    $M x=x^{k-1}$  , all coordinates of    $M x$   are bounded by

  $\Phi\|x\|_{\infty}$  and    $\|M x\|_{\infty}\leq\Phi\|x\|_{\infty}$  .  

Now consider general    $n$   and    $M\in\mathcal A^{n}$  ,    $M=F_{\delta_{n}}\cdot.\,.\,.\cdot F_{\delta_{1}}$  . We know that for any    $x\in\mathbb{R}^{k-1}$  ,

  $\|F_{\delta_{k-1}}\cdot.\,.\,.\,F_{\delta_{1}}x\|_{\infty}\leq\Phi\|x\|_{\infty}$  . Thus,    $\|F_{\delta_{2(k-1)}}\cdot.\,.\,.\,F_{\delta_{1}}x\|_{\infty}\leq\Phi\|F_{\delta_{k-1}}\cdot.\,.\,.\,F_{\delta_{1}}x\|_{\infty}\leq\Phi^{2}\|x\|_{\infty}$    n  and letting   $\begin{array}{r}{\tilde{n}=\left\lfloor\frac{n}{k-1}\right\rfloor}\end{array}$  by iterative back-substitution we get    $\|F_{\delta_{\tilde{n}(k-1)}}\cdot.\,.\,.\cdot F_{\delta_{1}}x\|_{\infty}\leq\Phi^{\tilde{n}}\|x\|_{\infty}$    . − − Finally note from (C.1) that applying    $F_{\delta}$   cannot increase the maximum norm, so that  

$$
\|M x\|_{\infty}=\|F_{\delta_{n}}\cdot.\,.\,.\,F_{\delta_{1}}x\|_{\infty}\leq\|F_{\delta_{\tilde{n}(k-1)}}\cdot.\,.\,.\,.\,F_{\delta_{1}}x\|_{\infty}\leq\Phi^{\tilde{n}}\|x\|_{\infty}.
$$  

If    $x$   is an eigenvector of    $M$   with the corresponding eigenvalue    $\lambda$  , we must have    $M x=\lambda x$  and    $\|M x\|_{\infty}=|\lambda|\cdot\|x\|_{\infty}$  . Since    $\|M x\|_{\infty}\leq\Phi^{\tilde{n}}\|x\|_{\infty}$  ∥ ∥ , we must also have    $|\lambda|\leq\Phi^{\tilde{n}}$  . Therefore, j  n k ∞  $\Phi^{\left\lfloor{\frac{n}{k-1}}\right\rfloor}$  the spectral radius of    $M$  ,    $\lambda(M)$  , is at most Φ , which completes the proof. □  

# References  

Andrews, D. W. K.  and  Chen, H. Y.  (1994). Approximately median-unbiased estimation of autoregressive models.  Journal of Business  &  Economic Statistics ,  12  (2), 187–204.  

Aruoba, S. B. ,  Mlikota, M. ,  Schorfheide, F.  and  Villalvazo, S.  (2022). SVARs with occasionally-binding constraints.  Journal of Econometrics ,  231  (2), 477–499.  

Baillie, R. T.  and  Bollerslev, T.  (1989). Common stochastic trends in a system of exchange rates.  Journal of Finance ,  44  (1), 167–181.  

Brezigar-Masten, A. ,  Masten, I.  and  Volk, M.  (2021). Modeling credit risk with a Tobit model of days past due.  Journal of Banking & Finance ,  122 , 105984.  

Brockwell, P. J.  and  Davis, R. A.  (1991).  Time Series: theory and methods . Springer. Bykhovskaya, A.  (2023). Time series approach to the evolution of networks: prediction and estimation.  Journal of Business & Economic Statistics ,  41  (1), 170–183. —  and  Phillips, P. C. B.  (2018). Boundary limit theory for functional local to unity regression.  Journal of Time Series Analysis ,  39  (4), 523–562. Cavaliere, G.  (2004). The asymptotic distribution of the Dickey–Fuller statistic under non- negativity constraint.  Econometric Theory ,  20  (4), 808–810.

 —  (2005). Limited time series with a unit root.  Econometric Theory ,  21  (5), 907–945.

 —  and  Xu, F.  (2014). Testing for unit roots in bounded time series.  Journal of Econometrics , 178 , 259–272. Chan, K.-S.  (ed.) (2009).  Exploration of a Nonlinear World: an appreciation of Howell Tong’s contributions to statistics . World Scientiﬁc. Chan, N. H.  and  Wei, C. Z.  (1987). Asymptotic inference for nearly nonstationary AR(1) processes.  Annals of Statistics , pp. 1050–1063. de Jong, R.  and  Herrera, A. M.  (2011). Dynamic censored regression and the Open Market Desk reaction function.  Journal of Business  &  Economic Statistics ,  29  (2), 228– 237. Demiralp, S.  and  Jord\` a, O.  (2002). The announcement eﬀect: evidence from Open Market Desk data.  FRBNY Economic Policy Review ,  8 , 29–48. Dickey, D. A.  and  Fuller, W. A.  (1979). Distribution of the estimators for autoregressive time series with a unit root.  Journal of the American Statistical Association ,  74  (366), 427–431. Dong, D. ,  Schmit, T. M.  and  Kaiser, H.  (2012). Modelling household purchasing beha- viour to analyse beneﬁcial marketing strategies.  Applied Economics ,  44  (6), 717–725. Duffy, J. A. ,  Mavroeidis, S.  and  Wycherley, S.  (2022). Cointegration with occasionally binding constraints, arXiv:2211.09604. Fan, J.  and  Yao, Q.  (2003).  Nonlinear Time Series: nonparametric and parametric methods . Springer. Gao, J.  (2007).  Nonlinear Time Series: semiparametric and nonparametric methods . Chap- man and Hall/CRC. — ,  Tjøstheim, D.  and  Yin, J.  (2013). Estimation in threshold autoregressive models with a stationary and a unit root regime.  Journal of Econometrics ,  172  (1), 1–13. Giraitis, L.  and  Phillips, P. C. B.  (2006). Uniform limit theory for stationary autore- gression.  Journal of Time Series Analysis ,  27  (1), 51–60. Hahn, J.  and  Kuersteiner, G.  (2010). Stationarity and mixing properties of the dynamic Tobit model.  Economics Letters ,  107  (2), 105–111. Hamilton, J. D.  (1994).  Time Series Analysis . Princeton, NJ (USA): Princeton University Press.  

Hamori, S.  and  Tokihisa, A.  (1997). Testing for a unit root in the presence of a variance shift.  Economics Letters ,  57  (3), 245–253. Hansen, B. E.  (1999). The grid bootstrap and the autoregressive model.  Review of Economics and Statistics ,  81  (4), 594–607. Hertrich, M.  (2022). Foreign exchange interventions under a minimum exchange rate regime and the Swiss franc.  Review of International Economics ,  30  (2), 450–489. Hong, S. H.  and  Phillips, P. C. B.  (2010). Testing linearity in cointegrating relations with an application to purchasing power parity.  Journal of Business & Economic Statistics , 28  (1), 96–114. Jordan, T. J.  (2016). The euro and Swiss monetary policy. Speech at the Europa Forum, Lucerne, 2 May. Jungers, R.  (2009).  The Joint Spectral Radius: theory and applications . Springer. Karatzas, I.  and  Shreve, S.  (2012).  Brownian Motion and Stochastic Calculus . Springer Science   $\&$   Business Media. Kim, T.-H. ,  Leybourne, S.  and  Newbold, P.  (2002). Unit root tests with a break in innovation variance.  Journal of Econometrics ,  109  (2), 365–387. Liang, H. ,  Phillips, P. C. B. ,  Wang, H.  and  Wang, Q.  (2016). Weak convergence to stochastic integrals for econometric applications.  Econometric Theory ,  32  (6), 1349–1375. Liebscher, E.  (2005). Towards a uniﬁed approach for proving geometric ergodicity and mixing properties of nonlinear autoregressive processes.  Journal of Time Series Analysis , 26  (5), 669–689. Liu, L. ,  Moon, H. R.  and  Schorfheide, F.  (2019). Forecasting with a panel Tobit model. NBER working paper 28571. Liu, W. ,  Ling, S.  and  Shao, Q.-M.  (2011). On non-stationary threshold autoregressive models.  Bernoulli ,  17  (3), 969–986. Maddala, G. S.  (1983).  Limited-Dependent and Qualitative Variables in Econometrics . USA: C.U.P. Mavroeidis, S.  (2021). Identiﬁcation at the zero lower bound.  Econometrica ,  69  (6), 2855– 2885. Michel, J.  and  de Jong, R.  (2018). Mixing properties of the dynamic tobit model with mixing errors.  Economics Letters ,  162 , 112–115. Mikusheva, A.  (2007). Uniform inference in autoregressive models.  Econometrica ,  75  (5), 1411–1452. —  (2012). One-dimensional inference in autoregressive models with the potential presence of a unit root.  Econometrica ,  80  (1), 173–212. Moran, P. A. P.  (1953). The statistical analysis of the Canadian lynx cycle, I: structure and prediction.  Australian Journal of Zoology ,  1 , 163–173.  

Parrilo, P. A.  and  Jadbabaie, A.  (2008). Approximation of the joint spectral radius using sum of squares.  Linear Algebra and its Applications ,  428  (10), 2385–2402. Phillips, P. C. B.  (1987a). Time series regression with a unit root.  Econometrica , pp. 277–301.

 —  (1987b). Towards a uniﬁed asymptotic theory for autoregression.  Biometrika ,  74  (3), 535– 547.

 —  and  Solo, V.  (1992). Asymptotics for linear processes.  Annals of Statistics ,  20  (2), 971– 1001. Revuz, D.  and  Yor, M.  (1999).  Continuous Martingales and Brownian Motion . Springer. Rossi, B.  (2013). Exchange rate predictability.  Journal of Economic Literature ,  51  (4), 1063– 1119. Saikkonen, P.  (2008). Stability of regime switching error correction models under linear cointegration.  Econometric Theory ,  24  (1), 294–318. Sarno, L.  and  Valente, G.  (2006). Deviations from purchasing power parity under diﬀerent exchange rate regimes: Do they revert and, if so, how?  Journal of Banking & Finance , 30  (11), 3147–3169. Terasvirta, T. ,  Tjøstheim, D.  and  Granger, C. W. J.  (2010).  Modelling Nonlinear Economic Time Series . O.U.P. Tobin, J.  (1958). Estimation of relationship for limited dependent variables.  Econometrica , 26  (1), 24–36. von Schweinitz, G. ,  Tonzer, L.  and  Buchholz, M.  (2021). Monetary policy through exchange rate pegs: the removal of the Swiss franc–euro ﬂoor and stock price reactions. International Review of Finance ,  21  (4), 1382–1406. Wang, C.-H.  and  De Jong, R. M.  (2013). Unit root tests when the data are a trigonometric transformation of an integrated process.  South African Statistical Journal ,  47  (1), 83–90. Wei, S. X.  (1999). A bayesian approach to dynamic Tobit models.  Econometric Reviews , 18  (4), 417–439. (Anna Bykhovskaya)  Duke University Email address :  anna.bykhovskaya@duke.edu  

(James A. Duﬀy)  University of Oxford Email address :  james.duffy@economics.ox.ac.uk  